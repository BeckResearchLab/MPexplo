{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import r2_score, matthews_corrcoef\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>AP_FP_2</th>\n",
       "      <th>AP_FP_3</th>\n",
       "      <th>AP_FP_4</th>\n",
       "      <th>AP_FP_5</th>\n",
       "      <th>AP_FP_6</th>\n",
       "      <th>AP_FP_460</th>\n",
       "      <th>AP_FP_1700</th>\n",
       "      <th>AP_FP_480</th>\n",
       "      <th>AP_FP_8</th>\n",
       "      <th>...</th>\n",
       "      <th>AP_FP_1787</th>\n",
       "      <th>AP_FP_2233</th>\n",
       "      <th>AP_FP_1542</th>\n",
       "      <th>AP_FP_3736</th>\n",
       "      <th>AP_FP_2696</th>\n",
       "      <th>AP_FP_130</th>\n",
       "      <th>AP_FP_4243</th>\n",
       "      <th>AP_FP_4314</th>\n",
       "      <th>AP_FP_4050</th>\n",
       "      <th>AP_FP_6622</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 997 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule  AP_FP_2  AP_FP_3  AP_FP_4  AP_FP_5  AP_FP_6  AP_FP_460  \\\n",
       "0  Compound0001        0        0        0        0        0          0   \n",
       "1  Compound0002        0        0        0        0        0          0   \n",
       "2  Compound0003        0        0        1        0        0          0   \n",
       "3  Compound0004        0        0        1        0        0          0   \n",
       "4  Compound0005        0        0        1        0        0          0   \n",
       "\n",
       "   AP_FP_1700  AP_FP_480  AP_FP_8     ...      AP_FP_1787  AP_FP_2233  \\\n",
       "0           0          0        0     ...               0           0   \n",
       "1           0          0        0     ...               0           0   \n",
       "2           0          0        0     ...               1           0   \n",
       "3           0          0        0     ...               1           0   \n",
       "4           0          0        0     ...               0           0   \n",
       "\n",
       "   AP_FP_1542  AP_FP_3736  AP_FP_2696  AP_FP_130  AP_FP_4243  AP_FP_4314  \\\n",
       "0           0           0           0          0           0           0   \n",
       "1           0           0           0          0           0           0   \n",
       "2           0           0           0          0           1           3   \n",
       "3           0           0           0          0           1           3   \n",
       "4           0           0           0          0           1           3   \n",
       "\n",
       "   AP_FP_4050  AP_FP_6622  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  \n",
       "\n",
       "[5 rows x 997 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atom=pd.read_csv('caco_AtomPair.tsv', sep='\\t', index_col=False)\n",
    "df_atom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule',\n",
       " 'ClogP',\n",
       " 'QikProp_.stars',\n",
       " 'QikProp_.amine',\n",
       " 'QikProp_.amidine',\n",
       " 'QikProp_.acid',\n",
       " 'QikProp_.amide',\n",
       " 'QikProp_.rotor',\n",
       " 'QikProp_.rtvFG',\n",
       " 'QikProp_CNS',\n",
       " 'QikProp_mol_MW',\n",
       " 'QikProp_dipole',\n",
       " 'QikProp_SASA',\n",
       " 'QikProp_FOSA',\n",
       " 'QikProp_FISA',\n",
       " 'QikProp_PISA',\n",
       " 'QikProp_WPSA',\n",
       " 'QikProp_volume',\n",
       " 'QikProp_donorHB',\n",
       " 'QikProp_accptHB',\n",
       " 'QikProp_dip.2.V',\n",
       " 'QikProp_ACxDN..5.SA',\n",
       " 'QikProp_glob',\n",
       " 'QikProp_QPpolrz',\n",
       " 'QikProp_QPlogPC16',\n",
       " 'QikProp_QPlogPoct',\n",
       " 'QikProp_QPlogPw',\n",
       " 'QikProp_QPlogPo.w',\n",
       " 'QikProp_QPlogS',\n",
       " 'QikProp_CIQPlogS',\n",
       " 'QikProp_QPlogHERG',\n",
       " 'QikProp_QPPCaco',\n",
       " 'QikProp_QPlogBB',\n",
       " 'QikProp_QPPMDCK',\n",
       " 'QikProp_QPlogKp',\n",
       " 'QikProp_IP.eV.',\n",
       " 'QikProp_EA.eV.',\n",
       " 'QikProp_.metab',\n",
       " 'QikProp_QPlogKhsa',\n",
       " 'QikProp_HumanOralAbsorption',\n",
       " 'QikProp_PercentHumanOralAbsorption',\n",
       " 'QikProp_SAfluorine',\n",
       " 'QikProp_SAamideO',\n",
       " 'QikProp_PSA',\n",
       " 'QikProp_.NandO',\n",
       " 'QikProp_RuleOfFive',\n",
       " 'QikProp_.ringatoms',\n",
       " 'QikProp_.in34',\n",
       " 'QikProp_.in56',\n",
       " 'QikProp_.noncon',\n",
       " 'QikProp_.nonHatm',\n",
       " 'QikProp_RuleOfThree',\n",
       " 'QikProp_ACxDN..5.SAxSASA.MW']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dragon=pd.read_csv('caco_Dragon.tsv', sep='\\t', index_col=False)\n",
    "df_dragon\n",
    "list(df_dragon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule',\n",
       " 'QikProp_.stars',\n",
       " 'QikProp_.amine',\n",
       " 'QikProp_.amidine',\n",
       " 'QikProp_.acid',\n",
       " 'QikProp_.amide',\n",
       " 'QikProp_.rotor',\n",
       " 'QikProp_.rtvFG',\n",
       " 'QikProp_CNS',\n",
       " 'QikProp_mol_MW',\n",
       " 'QikProp_dipole',\n",
       " 'QikProp_SASA',\n",
       " 'QikProp_FOSA',\n",
       " 'QikProp_FISA',\n",
       " 'QikProp_PISA',\n",
       " 'QikProp_WPSA',\n",
       " 'QikProp_volume',\n",
       " 'QikProp_donorHB',\n",
       " 'QikProp_accptHB',\n",
       " 'QikProp_dip.2.V',\n",
       " 'QikProp_ACxDN..5.SA',\n",
       " 'QikProp_glob',\n",
       " 'QikProp_QPpolrz',\n",
       " 'QikProp_QPlogPC16',\n",
       " 'QikProp_QPlogPoct',\n",
       " 'QikProp_QPlogPw',\n",
       " 'QikProp_QPlogPo.w',\n",
       " 'QikProp_QPlogS',\n",
       " 'QikProp_CIQPlogS',\n",
       " 'QikProp_QPlogHERG',\n",
       " 'QikProp_QPPCaco',\n",
       " 'QikProp_QPlogBB',\n",
       " 'QikProp_QPPMDCK',\n",
       " 'QikProp_QPlogKp',\n",
       " 'QikProp_IP.eV.',\n",
       " 'QikProp_EA.eV.',\n",
       " 'QikProp_.metab',\n",
       " 'QikProp_QPlogKhsa',\n",
       " 'QikProp_HumanOralAbsorption',\n",
       " 'QikProp_PercentHumanOralAbsorption',\n",
       " 'QikProp_SAfluorine',\n",
       " 'QikProp_SAamideO',\n",
       " 'QikProp_PSA',\n",
       " 'QikProp_.NandO',\n",
       " 'QikProp_RuleOfFive',\n",
       " 'QikProp_.ringatoms',\n",
       " 'QikProp_.in34',\n",
       " 'QikProp_.in56',\n",
       " 'QikProp_.noncon',\n",
       " 'QikProp_.nonHatm',\n",
       " 'QikProp_RuleOfThree',\n",
       " 'QikProp_ACxDN..5.SAxSASA.MW']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quick=pd.read_csv('caco_QuickProp.tsv', sep='\\t', index_col=False)\n",
    "list(df_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule',\n",
       " 'PPFP_FCFP_0001',\n",
       " 'PPFP_FCFP_0002',\n",
       " 'PPFP_FCFP_0003',\n",
       " 'PPFP_FCFP_0004',\n",
       " 'PPFP_FCFP_0005',\n",
       " 'PPFP_FCFP_0006',\n",
       " 'PPFP_FCFP_0007',\n",
       " 'PPFP_FCFP_0008',\n",
       " 'PPFP_FCFP_0009',\n",
       " 'PPFP_FCFP_0010',\n",
       " 'PPFP_FCFP_0011',\n",
       " 'PPFP_FCFP_0012',\n",
       " 'PPFP_FCFP_0013',\n",
       " 'PPFP_FCFP_0014',\n",
       " 'PPFP_FCFP_0015',\n",
       " 'PPFP_FCFP_0016',\n",
       " 'PPFP_FCFP_0017',\n",
       " 'PPFP_FCFP_0018',\n",
       " 'PPFP_FCFP_0019',\n",
       " 'PPFP_FCFP_0020',\n",
       " 'PPFP_FCFP_0021',\n",
       " 'PPFP_FCFP_0022',\n",
       " 'PPFP_FCFP_0023',\n",
       " 'PPFP_FCFP_0024',\n",
       " 'PPFP_FCFP_0025',\n",
       " 'PPFP_FCFP_0026',\n",
       " 'PPFP_FCFP_0027',\n",
       " 'PPFP_FCFP_0028',\n",
       " 'PPFP_FCFP_0029',\n",
       " 'PPFP_FCFP_0030',\n",
       " 'PPFP_FCFP_0031',\n",
       " 'PPFP_FCFP_0032',\n",
       " 'PPFP_FCFP_0033',\n",
       " 'PPFP_FCFP_0034',\n",
       " 'PPFP_FCFP_0035',\n",
       " 'PPFP_FCFP_0036',\n",
       " 'PPFP_FCFP_0037',\n",
       " 'PPFP_FCFP_0038',\n",
       " 'PPFP_FCFP_0039',\n",
       " 'PPFP_FCFP_0040',\n",
       " 'PPFP_FCFP_0041',\n",
       " 'PPFP_FCFP_0042',\n",
       " 'PPFP_FCFP_0043',\n",
       " 'PPFP_FCFP_0044',\n",
       " 'PPFP_FCFP_0045',\n",
       " 'PPFP_FCFP_0046',\n",
       " 'PPFP_FCFP_0047',\n",
       " 'PPFP_FCFP_0048',\n",
       " 'PPFP_FCFP_0049',\n",
       " 'PPFP_FCFP_0050',\n",
       " 'PPFP_FCFP_0051',\n",
       " 'PPFP_FCFP_0052',\n",
       " 'PPFP_FCFP_0053',\n",
       " 'PPFP_FCFP_0054',\n",
       " 'PPFP_FCFP_0055',\n",
       " 'PPFP_FCFP_0056',\n",
       " 'PPFP_FCFP_0057',\n",
       " 'PPFP_FCFP_0058',\n",
       " 'PPFP_FCFP_0059',\n",
       " 'PPFP_FCFP_0060',\n",
       " 'PPFP_FCFP_0061',\n",
       " 'PPFP_FCFP_0062',\n",
       " 'PPFP_FCFP_0063',\n",
       " 'PPFP_FCFP_0064',\n",
       " 'PPFP_FCFP_0065',\n",
       " 'PPFP_FCFP_0066',\n",
       " 'PPFP_FCFP_0067',\n",
       " 'PPFP_FCFP_0068',\n",
       " 'PPFP_FCFP_0069',\n",
       " 'PPFP_FCFP_0070',\n",
       " 'PPFP_FCFP_0071',\n",
       " 'PPFP_FCFP_0072',\n",
       " 'PPFP_FCFP_0073',\n",
       " 'PPFP_FCFP_0074',\n",
       " 'PPFP_FCFP_0075',\n",
       " 'PPFP_FCFP_0076',\n",
       " 'PPFP_FCFP_0077',\n",
       " 'PPFP_FCFP_0078',\n",
       " 'PPFP_FCFP_0079',\n",
       " 'PPFP_FCFP_0080',\n",
       " 'PPFP_FCFP_0081',\n",
       " 'PPFP_FCFP_0082',\n",
       " 'PPFP_FCFP_0083',\n",
       " 'PPFP_FCFP_0084',\n",
       " 'PPFP_FCFP_0085',\n",
       " 'PPFP_FCFP_0086',\n",
       " 'PPFP_FCFP_0087',\n",
       " 'PPFP_FCFP_0088',\n",
       " 'PPFP_FCFP_0089',\n",
       " 'PPFP_FCFP_0090',\n",
       " 'PPFP_FCFP_0091',\n",
       " 'PPFP_FCFP_0092',\n",
       " 'PPFP_FCFP_0093',\n",
       " 'PPFP_FCFP_0094',\n",
       " 'PPFP_FCFP_0095',\n",
       " 'PPFP_FCFP_0096',\n",
       " 'PPFP_FCFP_0097',\n",
       " 'PPFP_FCFP_0098',\n",
       " 'PPFP_FCFP_0099',\n",
       " 'PPFP_FCFP_0100',\n",
       " 'PPFP_FCFP_0101',\n",
       " 'PPFP_FCFP_0102',\n",
       " 'PPFP_FCFP_0103',\n",
       " 'PPFP_FCFP_0104',\n",
       " 'PPFP_FCFP_0105',\n",
       " 'PPFP_FCFP_0106',\n",
       " 'PPFP_FCFP_0107',\n",
       " 'PPFP_FCFP_0108',\n",
       " 'PPFP_FCFP_0109',\n",
       " 'PPFP_FCFP_0110',\n",
       " 'PPFP_FCFP_0111',\n",
       " 'PPFP_FCFP_0112',\n",
       " 'PPFP_FCFP_0113',\n",
       " 'PPFP_FCFP_0114',\n",
       " 'PPFP_FCFP_0115',\n",
       " 'PPFP_FCFP_0116',\n",
       " 'PPFP_FCFP_0117',\n",
       " 'PPFP_FCFP_0118',\n",
       " 'PPFP_FCFP_0119',\n",
       " 'PPFP_FCFP_0120',\n",
       " 'PPFP_FCFP_0121',\n",
       " 'PPFP_FCFP_0122',\n",
       " 'PPFP_FCFP_0123',\n",
       " 'PPFP_FCFP_0124',\n",
       " 'PPFP_FCFP_0125',\n",
       " 'PPFP_FCFP_0126',\n",
       " 'PPFP_FCFP_0127',\n",
       " 'PPFP_FCFP_0128',\n",
       " 'PPFP_FCFP_0129',\n",
       " 'PPFP_FCFP_0130',\n",
       " 'PPFP_FCFP_0131',\n",
       " 'PPFP_FCFP_0132',\n",
       " 'PPFP_FCFP_0133',\n",
       " 'PPFP_FCFP_0134',\n",
       " 'PPFP_FCFP_0135',\n",
       " 'PPFP_FCFP_0136',\n",
       " 'PPFP_FCFP_0137',\n",
       " 'PPFP_FCFP_0138',\n",
       " 'PPFP_FCFP_0139',\n",
       " 'PPFP_FCFP_0140',\n",
       " 'PPFP_FCFP_0141',\n",
       " 'PPFP_FCFP_0142',\n",
       " 'PPFP_FCFP_0143',\n",
       " 'PPFP_FCFP_0144',\n",
       " 'PPFP_FCFP_0145',\n",
       " 'PPFP_FCFP_0146',\n",
       " 'PPFP_FCFP_0147',\n",
       " 'PPFP_FCFP_0148',\n",
       " 'PPFP_FCFP_0149',\n",
       " 'PPFP_FCFP_0150',\n",
       " 'PPFP_FCFP_0151',\n",
       " 'PPFP_FCFP_0152',\n",
       " 'PPFP_FCFP_0153',\n",
       " 'PPFP_FCFP_0154',\n",
       " 'PPFP_FCFP_0155',\n",
       " 'PPFP_FCFP_0156',\n",
       " 'PPFP_FCFP_0157',\n",
       " 'PPFP_FCFP_0158',\n",
       " 'PPFP_FCFP_0159',\n",
       " 'PPFP_FCFP_0160',\n",
       " 'PPFP_FCFP_0161',\n",
       " 'PPFP_FCFP_0162',\n",
       " 'PPFP_FCFP_0163',\n",
       " 'PPFP_FCFP_0164',\n",
       " 'PPFP_FCFP_0165',\n",
       " 'PPFP_FCFP_0166',\n",
       " 'PPFP_FCFP_0167',\n",
       " 'PPFP_FCFP_0168',\n",
       " 'PPFP_FCFP_0169',\n",
       " 'PPFP_FCFP_0170',\n",
       " 'PPFP_FCFP_0171',\n",
       " 'PPFP_FCFP_0172',\n",
       " 'PPFP_FCFP_0173',\n",
       " 'PPFP_FCFP_0174',\n",
       " 'PPFP_FCFP_0175',\n",
       " 'PPFP_FCFP_0176',\n",
       " 'PPFP_FCFP_0177',\n",
       " 'PPFP_FCFP_0178',\n",
       " 'PPFP_FCFP_0179',\n",
       " 'PPFP_FCFP_0180',\n",
       " 'PPFP_FCFP_0181',\n",
       " 'PPFP_FCFP_0182',\n",
       " 'PPFP_FCFP_0183',\n",
       " 'PPFP_FCFP_0184',\n",
       " 'PPFP_FCFP_0185',\n",
       " 'PPFP_FCFP_0186',\n",
       " 'PPFP_FCFP_0187',\n",
       " 'PPFP_FCFP_0188',\n",
       " 'PPFP_FCFP_0189',\n",
       " 'PPFP_FCFP_0190',\n",
       " 'PPFP_FCFP_0191',\n",
       " 'PPFP_FCFP_0192',\n",
       " 'PPFP_FCFP_0193',\n",
       " 'PPFP_FCFP_0194',\n",
       " 'PPFP_FCFP_0195',\n",
       " 'PPFP_FCFP_0196',\n",
       " 'PPFP_FCFP_0197',\n",
       " 'PPFP_FCFP_0198',\n",
       " 'PPFP_FCFP_0199',\n",
       " 'PPFP_FCFP_0200',\n",
       " 'PPFP_FCFP_0201',\n",
       " 'PPFP_FCFP_0202',\n",
       " 'PPFP_FCFP_0203',\n",
       " 'PPFP_FCFP_0204',\n",
       " 'PPFP_FCFP_0205',\n",
       " 'PPFP_FCFP_0206',\n",
       " 'PPFP_FCFP_0207',\n",
       " 'PPFP_FCFP_0208',\n",
       " 'PPFP_FCFP_0209',\n",
       " 'PPFP_FCFP_0210',\n",
       " 'PPFP_FCFP_0211',\n",
       " 'PPFP_FCFP_0212',\n",
       " 'PPFP_FCFP_0213',\n",
       " 'PPFP_FCFP_0214',\n",
       " 'PPFP_FCFP_0215',\n",
       " 'PPFP_FCFP_0216',\n",
       " 'PPFP_FCFP_0217',\n",
       " 'PPFP_FCFP_0218',\n",
       " 'PPFP_FCFP_0219',\n",
       " 'PPFP_FCFP_0220',\n",
       " 'PPFP_FCFP_0221',\n",
       " 'PPFP_FCFP_0222',\n",
       " 'PPFP_FCFP_0223',\n",
       " 'PPFP_FCFP_0224',\n",
       " 'PPFP_FCFP_0225',\n",
       " 'PPFP_FCFP_0226',\n",
       " 'PPFP_FCFP_0227',\n",
       " 'PPFP_FCFP_0228',\n",
       " 'PPFP_FCFP_0229',\n",
       " 'PPFP_FCFP_0230',\n",
       " 'PPFP_FCFP_0231',\n",
       " 'PPFP_FCFP_0232',\n",
       " 'PPFP_FCFP_0233',\n",
       " 'PPFP_FCFP_0234',\n",
       " 'PPFP_FCFP_0235',\n",
       " 'PPFP_FCFP_0236',\n",
       " 'PPFP_FCFP_0237',\n",
       " 'PPFP_FCFP_0238',\n",
       " 'PPFP_FCFP_0239',\n",
       " 'PPFP_FCFP_0240',\n",
       " 'PPFP_FCFP_0241',\n",
       " 'PPFP_FCFP_0242',\n",
       " 'PPFP_FCFP_0243',\n",
       " 'PPFP_FCFP_0244',\n",
       " 'PPFP_FCFP_0245',\n",
       " 'PPFP_FCFP_0246',\n",
       " 'PPFP_FCFP_0247',\n",
       " 'PPFP_FCFP_0248',\n",
       " 'PPFP_FCFP_0249',\n",
       " 'PPFP_FCFP_0250',\n",
       " 'PPFP_FCFP_0251',\n",
       " 'PPFP_FCFP_0252',\n",
       " 'PPFP_FCFP_0253',\n",
       " 'PPFP_FCFP_0254',\n",
       " 'PPFP_FCFP_0255',\n",
       " 'PPFP_FCFP_0256',\n",
       " 'PPFP_FCFP_0257',\n",
       " 'PPFP_FCFP_0258',\n",
       " 'PPFP_FCFP_0259',\n",
       " 'PPFP_FCFP_0260',\n",
       " 'PPFP_FCFP_0261',\n",
       " 'PPFP_FCFP_0262',\n",
       " 'PPFP_FCFP_0263',\n",
       " 'PPFP_FCFP_0264',\n",
       " 'PPFP_FCFP_0265',\n",
       " 'PPFP_FCFP_0266',\n",
       " 'PPFP_FCFP_0267',\n",
       " 'PPFP_FCFP_0268',\n",
       " 'PPFP_FCFP_0269',\n",
       " 'PPFP_FCFP_0270',\n",
       " 'PPFP_FCFP_0271',\n",
       " 'PPFP_FCFP_0272',\n",
       " 'PPFP_FCFP_0273',\n",
       " 'PPFP_FCFP_0274',\n",
       " 'PPFP_FCFP_0275',\n",
       " 'PPFP_FCFP_0276',\n",
       " 'PPFP_FCFP_0277',\n",
       " 'PPFP_FCFP_0278',\n",
       " 'PPFP_FCFP_0279',\n",
       " 'PPFP_FCFP_0280',\n",
       " 'PPFP_FCFP_0281',\n",
       " 'PPFP_FCFP_0282',\n",
       " 'PPFP_FCFP_0283',\n",
       " 'PPFP_FCFP_0284',\n",
       " 'PPFP_FCFP_0285',\n",
       " 'PPFP_FCFP_0286',\n",
       " 'PPFP_FCFP_0287',\n",
       " 'PPFP_FCFP_0288',\n",
       " 'PPFP_FCFP_0289',\n",
       " 'PPFP_FCFP_0290',\n",
       " 'PPFP_FCFP_0291',\n",
       " 'PPFP_FCFP_0292',\n",
       " 'PPFP_FCFP_0293',\n",
       " 'PPFP_FCFP_0294',\n",
       " 'PPFP_FCFP_0295',\n",
       " 'PPFP_FCFP_0296',\n",
       " 'PPFP_FCFP_0297',\n",
       " 'PPFP_FCFP_0298',\n",
       " 'PPFP_FCFP_0299',\n",
       " 'PPFP_FCFP_0300',\n",
       " 'PPFP_FCFP_0301',\n",
       " 'PPFP_FCFP_0302',\n",
       " 'PPFP_FCFP_0303',\n",
       " 'PPFP_FCFP_0304',\n",
       " 'PPFP_FCFP_0305',\n",
       " 'PPFP_FCFP_0306',\n",
       " 'PPFP_FCFP_0307',\n",
       " 'PPFP_FCFP_0308',\n",
       " 'PPFP_FCFP_0309',\n",
       " 'PPFP_FCFP_0310',\n",
       " 'PPFP_FCFP_0311',\n",
       " 'PPFP_FCFP_0312',\n",
       " 'PPFP_FCFP_0313',\n",
       " 'PPFP_FCFP_0314',\n",
       " 'PPFP_FCFP_0315',\n",
       " 'PPFP_FCFP_0316',\n",
       " 'PPFP_FCFP_0317',\n",
       " 'PPFP_FCFP_0318',\n",
       " 'PPFP_FCFP_0319',\n",
       " 'PPFP_FCFP_0320',\n",
       " 'PPFP_FCFP_0321',\n",
       " 'PPFP_FCFP_0322',\n",
       " 'PPFP_FCFP_0323',\n",
       " 'PPFP_FCFP_0324',\n",
       " 'PPFP_FCFP_0325',\n",
       " 'PPFP_FCFP_0326',\n",
       " 'PPFP_FCFP_0327',\n",
       " 'PPFP_FCFP_0328',\n",
       " 'PPFP_FCFP_0329',\n",
       " 'PPFP_FCFP_0330',\n",
       " 'PPFP_FCFP_0331',\n",
       " 'PPFP_FCFP_0332',\n",
       " 'PPFP_FCFP_0333',\n",
       " 'PPFP_FCFP_0334',\n",
       " 'PPFP_FCFP_0335',\n",
       " 'PPFP_FCFP_0336',\n",
       " 'PPFP_FCFP_0337',\n",
       " 'PPFP_FCFP_0338',\n",
       " 'PPFP_FCFP_0339',\n",
       " 'PPFP_FCFP_0340',\n",
       " 'PPFP_FCFP_0341',\n",
       " 'PPFP_FCFP_0342',\n",
       " 'PPFP_FCFP_0343',\n",
       " 'PPFP_FCFP_0344',\n",
       " 'PPFP_FCFP_0345',\n",
       " 'PPFP_FCFP_0346',\n",
       " 'PPFP_FCFP_0347',\n",
       " 'PPFP_FCFP_0348',\n",
       " 'PPFP_FCFP_0349',\n",
       " 'PPFP_FCFP_0350',\n",
       " 'PPFP_FCFP_0351',\n",
       " 'PPFP_FCFP_0352',\n",
       " 'PPFP_FCFP_0353',\n",
       " 'PPFP_FCFP_0354',\n",
       " 'PPFP_FCFP_0355',\n",
       " 'PPFP_FCFP_0356',\n",
       " 'PPFP_FCFP_0357',\n",
       " 'PPFP_FCFP_0358',\n",
       " 'PPFP_FCFP_0359',\n",
       " 'PPFP_FCFP_0360',\n",
       " 'PPFP_FCFP_0361',\n",
       " 'PPFP_FCFP_0362',\n",
       " 'PPFP_FCFP_0363',\n",
       " 'PPFP_FCFP_0364',\n",
       " 'PPFP_FCFP_0365',\n",
       " 'PPFP_FCFP_0366',\n",
       " 'PPFP_FCFP_0367',\n",
       " 'PPFP_FCFP_0368',\n",
       " 'PPFP_FCFP_0369',\n",
       " 'PPFP_FCFP_0370',\n",
       " 'PPFP_FCFP_0371',\n",
       " 'PPFP_FCFP_0372',\n",
       " 'PPFP_FCFP_0373',\n",
       " 'PPFP_FCFP_0374',\n",
       " 'PPFP_FCFP_0375',\n",
       " 'PPFP_FCFP_0376',\n",
       " 'PPFP_FCFP_0377',\n",
       " 'PPFP_FCFP_0378',\n",
       " 'PPFP_FCFP_0379',\n",
       " 'PPFP_FCFP_0380',\n",
       " 'PPFP_FCFP_0381',\n",
       " 'PPFP_FCFP_0382',\n",
       " 'PPFP_FCFP_0383',\n",
       " 'PPFP_FCFP_0384',\n",
       " 'PPFP_FCFP_0385',\n",
       " 'PPFP_FCFP_0386',\n",
       " 'PPFP_FCFP_0387',\n",
       " 'PPFP_FCFP_0388',\n",
       " 'PPFP_FCFP_0389',\n",
       " 'PPFP_FCFP_0390',\n",
       " 'PPFP_FCFP_0391',\n",
       " 'PPFP_FCFP_0392',\n",
       " 'PPFP_FCFP_0393',\n",
       " 'PPFP_FCFP_0394',\n",
       " 'PPFP_FCFP_0395',\n",
       " 'PPFP_FCFP_0396',\n",
       " 'PPFP_FCFP_0397',\n",
       " 'PPFP_FCFP_0398',\n",
       " 'PPFP_FCFP_0399',\n",
       " 'PPFP_FCFP_0400',\n",
       " 'PPFP_FCFP_0401',\n",
       " 'PPFP_FCFP_0402',\n",
       " 'PPFP_FCFP_0403',\n",
       " 'PPFP_FCFP_0404',\n",
       " 'PPFP_FCFP_0405',\n",
       " 'PPFP_FCFP_0406',\n",
       " 'PPFP_FCFP_0407',\n",
       " 'PPFP_FCFP_0408',\n",
       " 'PPFP_FCFP_0409',\n",
       " 'PPFP_FCFP_0410',\n",
       " 'PPFP_FCFP_0411',\n",
       " 'PPFP_FCFP_0412',\n",
       " 'PPFP_FCFP_0413',\n",
       " 'PPFP_FCFP_0414',\n",
       " 'PPFP_FCFP_0415',\n",
       " 'PPFP_FCFP_0416',\n",
       " 'PPFP_FCFP_0417',\n",
       " 'PPFP_FCFP_0418',\n",
       " 'PPFP_FCFP_0419',\n",
       " 'PPFP_FCFP_0420',\n",
       " 'PPFP_FCFP_0421',\n",
       " 'PPFP_FCFP_0422',\n",
       " 'PPFP_FCFP_0423',\n",
       " 'PPFP_FCFP_0424',\n",
       " 'PPFP_FCFP_0425',\n",
       " 'PPFP_FCFP_0426',\n",
       " 'PPFP_FCFP_0427',\n",
       " 'PPFP_FCFP_0428',\n",
       " 'PPFP_FCFP_0429',\n",
       " 'PPFP_FCFP_0430',\n",
       " 'PPFP_FCFP_0431',\n",
       " 'PPFP_FCFP_0432',\n",
       " 'PPFP_FCFP_0433',\n",
       " 'PPFP_FCFP_0434',\n",
       " 'PPFP_FCFP_0435',\n",
       " 'PPFP_FCFP_0436',\n",
       " 'PPFP_FCFP_0437',\n",
       " 'PPFP_FCFP_0438',\n",
       " 'PPFP_FCFP_0439',\n",
       " 'PPFP_FCFP_0440',\n",
       " 'PPFP_FCFP_0441',\n",
       " 'PPFP_FCFP_0442',\n",
       " 'PPFP_FCFP_0443',\n",
       " 'PPFP_FCFP_0444',\n",
       " 'PPFP_FCFP_0445',\n",
       " 'PPFP_FCFP_0446',\n",
       " 'PPFP_FCFP_0447',\n",
       " 'PPFP_FCFP_0448',\n",
       " 'PPFP_FCFP_0449',\n",
       " 'PPFP_FCFP_0450',\n",
       " 'PPFP_FCFP_0451',\n",
       " 'PPFP_FCFP_0452',\n",
       " 'PPFP_FCFP_0453',\n",
       " 'PPFP_FCFP_0454',\n",
       " 'PPFP_FCFP_0455',\n",
       " 'PPFP_FCFP_0456',\n",
       " 'PPFP_FCFP_0457',\n",
       " 'PPFP_FCFP_0458',\n",
       " 'PPFP_FCFP_0459',\n",
       " 'PPFP_FCFP_0460',\n",
       " 'PPFP_FCFP_0461',\n",
       " 'PPFP_FCFP_0462',\n",
       " 'PPFP_FCFP_0463',\n",
       " 'PPFP_FCFP_0464',\n",
       " 'PPFP_FCFP_0465',\n",
       " 'PPFP_FCFP_0466',\n",
       " 'PPFP_FCFP_0467',\n",
       " 'PPFP_FCFP_0468',\n",
       " 'PPFP_FCFP_0469',\n",
       " 'PPFP_FCFP_0470',\n",
       " 'PPFP_FCFP_0471',\n",
       " 'PPFP_FCFP_0472',\n",
       " 'PPFP_FCFP_0473',\n",
       " 'PPFP_FCFP_0474',\n",
       " 'PPFP_FCFP_0475',\n",
       " 'PPFP_FCFP_0476',\n",
       " 'PPFP_FCFP_0477',\n",
       " 'PPFP_FCFP_0478',\n",
       " 'PPFP_FCFP_0479',\n",
       " 'PPFP_FCFP_0480',\n",
       " 'PPFP_FCFP_0481',\n",
       " 'PPFP_FCFP_0482',\n",
       " 'PPFP_FCFP_0483',\n",
       " 'PPFP_FCFP_0484',\n",
       " 'PPFP_FCFP_0485',\n",
       " 'PPFP_FCFP_0486',\n",
       " 'PPFP_FCFP_0487',\n",
       " 'PPFP_FCFP_0488',\n",
       " 'PPFP_FCFP_0489',\n",
       " 'PPFP_FCFP_0490',\n",
       " 'PPFP_FCFP_0491',\n",
       " 'PPFP_FCFP_0492',\n",
       " 'PPFP_FCFP_0493',\n",
       " 'PPFP_FCFP_0494',\n",
       " 'PPFP_FCFP_0495',\n",
       " 'PPFP_FCFP_0496',\n",
       " 'PPFP_FCFP_0497',\n",
       " 'PPFP_FCFP_0498',\n",
       " 'PPFP_FCFP_0499',\n",
       " 'PPFP_FCFP_0500',\n",
       " 'PPFP_FCFP_0501',\n",
       " 'PPFP_FCFP_0502',\n",
       " 'PPFP_FCFP_0503',\n",
       " 'PPFP_FCFP_0504',\n",
       " 'PPFP_FCFP_0505',\n",
       " 'PPFP_FCFP_0506',\n",
       " 'PPFP_FCFP_0507',\n",
       " 'PPFP_FCFP_0508',\n",
       " 'PPFP_FCFP_0509',\n",
       " 'PPFP_FCFP_0510',\n",
       " 'PPFP_FCFP_0511',\n",
       " 'PPFP_FCFP_0512',\n",
       " 'PPFP_FCFP_0513',\n",
       " 'PPFP_FCFP_0514',\n",
       " 'PPFP_FCFP_0515',\n",
       " 'PPFP_FCFP_0516',\n",
       " 'PPFP_FCFP_0517',\n",
       " 'PPFP_FCFP_0518',\n",
       " 'PPFP_FCFP_0519',\n",
       " 'PPFP_FCFP_0520',\n",
       " 'PPFP_FCFP_0521',\n",
       " 'PPFP_FCFP_0522',\n",
       " 'PPFP_FCFP_0523',\n",
       " 'PPFP_FCFP_0524',\n",
       " 'PPFP_FCFP_0525',\n",
       " 'PPFP_FCFP_0526',\n",
       " 'PPFP_FCFP_0527',\n",
       " 'PPFP_FCFP_0528',\n",
       " 'PPFP_FCFP_0529',\n",
       " 'PPFP_FCFP_0530',\n",
       " 'PPFP_FCFP_0531',\n",
       " 'PPFP_FCFP_0532',\n",
       " 'PPFP_FCFP_0533',\n",
       " 'PPFP_FCFP_0534',\n",
       " 'PPFP_FCFP_0535',\n",
       " 'PPFP_FCFP_0536',\n",
       " 'PPFP_FCFP_0537',\n",
       " 'PPFP_FCFP_0538',\n",
       " 'PPFP_FCFP_0539',\n",
       " 'PPFP_FCFP_0540',\n",
       " 'PPFP_FCFP_0541',\n",
       " 'PPFP_FCFP_0542',\n",
       " 'PPFP_FCFP_0543',\n",
       " 'PPFP_FCFP_0544',\n",
       " 'PPFP_FCFP_0545',\n",
       " 'PPFP_FCFP_0546',\n",
       " 'PPFP_FCFP_0547',\n",
       " 'PPFP_FCFP_0548',\n",
       " 'PPFP_FCFP_0549',\n",
       " 'PPFP_FCFP_0550',\n",
       " 'PPFP_FCFP_0551',\n",
       " 'PPFP_FCFP_0552',\n",
       " 'PPFP_FCFP_0553',\n",
       " 'PPFP_FCFP_0554',\n",
       " 'PPFP_FCFP_0555',\n",
       " 'PPFP_FCFP_0556',\n",
       " 'PPFP_FCFP_0557',\n",
       " 'PPFP_FCFP_0558',\n",
       " 'PPFP_FCFP_0559',\n",
       " 'PPFP_FCFP_0560',\n",
       " 'PPFP_FCFP_0561',\n",
       " 'PPFP_FCFP_0562',\n",
       " 'PPFP_FCFP_0563',\n",
       " 'PPFP_FCFP_0564',\n",
       " 'PPFP_FCFP_0565',\n",
       " 'PPFP_FCFP_0566',\n",
       " 'PPFP_FCFP_0567',\n",
       " 'PPFP_FCFP_0568',\n",
       " 'PPFP_FCFP_0569',\n",
       " 'PPFP_FCFP_0570',\n",
       " 'PPFP_FCFP_0571',\n",
       " 'PPFP_FCFP_0572',\n",
       " 'PPFP_FCFP_0573',\n",
       " 'PPFP_FCFP_0574',\n",
       " 'PPFP_FCFP_0575',\n",
       " 'PPFP_FCFP_0576',\n",
       " 'PPFP_FCFP_0577',\n",
       " 'PPFP_FCFP_0578',\n",
       " 'PPFP_FCFP_0579',\n",
       " 'PPFP_FCFP_0580',\n",
       " 'PPFP_FCFP_0581',\n",
       " 'PPFP_FCFP_0582',\n",
       " 'PPFP_FCFP_0583',\n",
       " 'PPFP_FCFP_0584',\n",
       " 'PPFP_FCFP_0585',\n",
       " 'PPFP_FCFP_0586',\n",
       " 'PPFP_FCFP_0587',\n",
       " 'PPFP_FCFP_0588',\n",
       " 'PPFP_FCFP_0589',\n",
       " 'PPFP_FCFP_0590',\n",
       " 'PPFP_FCFP_0591',\n",
       " 'PPFP_FCFP_0592',\n",
       " 'PPFP_FCFP_0593',\n",
       " 'PPFP_FCFP_0594',\n",
       " 'PPFP_FCFP_0595',\n",
       " 'PPFP_FCFP_0596',\n",
       " 'PPFP_FCFP_0597',\n",
       " 'PPFP_FCFP_0598',\n",
       " 'PPFP_FCFP_0599',\n",
       " 'PPFP_FCFP_0600',\n",
       " 'PPFP_FCFP_0601',\n",
       " 'PPFP_FCFP_0602',\n",
       " 'PPFP_FCFP_0603',\n",
       " 'PPFP_FCFP_0604',\n",
       " 'PPFP_FCFP_0605',\n",
       " 'PPFP_FCFP_0606',\n",
       " 'PPFP_FCFP_0607',\n",
       " 'PPFP_FCFP_0608',\n",
       " 'PPFP_FCFP_0609',\n",
       " 'PPFP_FCFP_0610',\n",
       " 'PPFP_FCFP_0611',\n",
       " 'PPFP_FCFP_0612',\n",
       " 'PPFP_FCFP_0613',\n",
       " 'PPFP_FCFP_0614',\n",
       " 'PPFP_FCFP_0615',\n",
       " 'PPFP_FCFP_0616',\n",
       " 'PPFP_FCFP_0617',\n",
       " 'PPFP_FCFP_0618',\n",
       " 'PPFP_FCFP_0619',\n",
       " 'PPFP_FCFP_0620',\n",
       " 'PPFP_FCFP_0621',\n",
       " 'PPFP_FCFP_0622',\n",
       " 'PPFP_FCFP_0623',\n",
       " 'PPFP_FCFP_0624',\n",
       " 'PPFP_FCFP_0625',\n",
       " 'PPFP_FCFP_0626',\n",
       " 'PPFP_FCFP_0627',\n",
       " 'PPFP_FCFP_0628',\n",
       " 'PPFP_FCFP_0629',\n",
       " 'PPFP_FCFP_0630',\n",
       " 'PPFP_FCFP_0631',\n",
       " 'PPFP_FCFP_0632',\n",
       " 'PPFP_FCFP_0633',\n",
       " 'PPFP_FCFP_0634',\n",
       " 'PPFP_FCFP_0635',\n",
       " 'PPFP_FCFP_0636',\n",
       " 'PPFP_FCFP_0637',\n",
       " 'PPFP_FCFP_0638',\n",
       " 'PPFP_FCFP_0639',\n",
       " 'PPFP_FCFP_0640',\n",
       " 'PPFP_FCFP_0641',\n",
       " 'PPFP_FCFP_0642',\n",
       " 'PPFP_FCFP_0643',\n",
       " 'PPFP_FCFP_0644',\n",
       " 'PPFP_FCFP_0645',\n",
       " 'PPFP_FCFP_0646',\n",
       " 'PPFP_FCFP_0647',\n",
       " 'PPFP_FCFP_0648',\n",
       " 'PPFP_FCFP_0649',\n",
       " 'PPFP_FCFP_0650',\n",
       " 'PPFP_FCFP_0651',\n",
       " 'PPFP_FCFP_0652',\n",
       " 'PPFP_FCFP_0653',\n",
       " 'PPFP_FCFP_0654',\n",
       " 'PPFP_FCFP_0655',\n",
       " 'PPFP_FCFP_0656',\n",
       " 'PPFP_FCFP_0657',\n",
       " 'PPFP_FCFP_0658',\n",
       " 'PPFP_FCFP_0659',\n",
       " 'PPFP_FCFP_0660',\n",
       " 'PPFP_FCFP_0661',\n",
       " 'PPFP_FCFP_0662',\n",
       " 'PPFP_FCFP_0663',\n",
       " 'PPFP_FCFP_0664',\n",
       " 'PPFP_FCFP_0665',\n",
       " 'PPFP_FCFP_0666',\n",
       " 'PPFP_FCFP_0667',\n",
       " 'PPFP_FCFP_0668',\n",
       " 'PPFP_FCFP_0669',\n",
       " 'PPFP_FCFP_0670',\n",
       " 'PPFP_FCFP_0671',\n",
       " 'PPFP_FCFP_0672',\n",
       " 'PPFP_FCFP_0673',\n",
       " 'PPFP_FCFP_0674',\n",
       " 'PPFP_FCFP_0675',\n",
       " 'PPFP_FCFP_0676',\n",
       " 'PPFP_FCFP_0677',\n",
       " 'PPFP_FCFP_0678',\n",
       " 'PPFP_FCFP_0679',\n",
       " 'PPFP_FCFP_0680',\n",
       " 'PPFP_FCFP_0681',\n",
       " 'PPFP_FCFP_0682',\n",
       " 'PPFP_FCFP_0683',\n",
       " 'PPFP_FCFP_0684',\n",
       " 'PPFP_FCFP_0685',\n",
       " 'PPFP_FCFP_0686',\n",
       " 'PPFP_FCFP_0687',\n",
       " 'PPFP_FCFP_0688',\n",
       " 'PPFP_FCFP_0689',\n",
       " 'PPFP_FCFP_0690',\n",
       " 'PPFP_FCFP_0691',\n",
       " 'PPFP_FCFP_0692',\n",
       " 'PPFP_FCFP_0693',\n",
       " 'PPFP_FCFP_0694',\n",
       " 'PPFP_FCFP_0695',\n",
       " 'PPFP_FCFP_0696',\n",
       " 'PPFP_FCFP_0697',\n",
       " 'PPFP_FCFP_0698',\n",
       " 'PPFP_FCFP_0699',\n",
       " 'PPFP_FCFP_0700',\n",
       " 'PPFP_FCFP_0701',\n",
       " 'PPFP_FCFP_0702',\n",
       " 'PPFP_FCFP_0703',\n",
       " 'PPFP_FCFP_0704',\n",
       " 'PPFP_FCFP_0705',\n",
       " 'PPFP_FCFP_0706',\n",
       " 'PPFP_FCFP_0707',\n",
       " 'PPFP_FCFP_0708',\n",
       " 'PPFP_FCFP_0709',\n",
       " 'PPFP_FCFP_0710',\n",
       " 'PPFP_FCFP_0711',\n",
       " 'PPFP_FCFP_0712',\n",
       " 'PPFP_FCFP_0713',\n",
       " 'PPFP_FCFP_0714',\n",
       " 'PPFP_FCFP_0715',\n",
       " 'PPFP_FCFP_0716',\n",
       " 'PPFP_FCFP_0717',\n",
       " 'PPFP_FCFP_0718',\n",
       " 'PPFP_FCFP_0719',\n",
       " 'PPFP_FCFP_0720',\n",
       " 'PPFP_FCFP_0721',\n",
       " 'PPFP_FCFP_0722',\n",
       " 'PPFP_FCFP_0723',\n",
       " 'PPFP_FCFP_0724',\n",
       " 'PPFP_FCFP_0725',\n",
       " 'PPFP_FCFP_0726',\n",
       " 'PPFP_FCFP_0727',\n",
       " 'PPFP_FCFP_0728',\n",
       " 'PPFP_FCFP_0729',\n",
       " 'PPFP_FCFP_0730',\n",
       " 'PPFP_FCFP_0731',\n",
       " 'PPFP_FCFP_0732',\n",
       " 'PPFP_FCFP_0733',\n",
       " 'PPFP_FCFP_0734',\n",
       " 'PPFP_FCFP_0735',\n",
       " 'PPFP_FCFP_0736',\n",
       " 'PPFP_FCFP_0737',\n",
       " 'PPFP_FCFP_0738',\n",
       " 'PPFP_FCFP_0739',\n",
       " 'PPFP_FCFP_0740',\n",
       " 'PPFP_FCFP_0741',\n",
       " 'PPFP_FCFP_0742',\n",
       " 'PPFP_FCFP_0743',\n",
       " 'PPFP_FCFP_0744',\n",
       " 'PPFP_FCFP_0745',\n",
       " 'PPFP_FCFP_0746',\n",
       " 'PPFP_FCFP_0747',\n",
       " 'PPFP_FCFP_0748',\n",
       " 'PPFP_FCFP_0749',\n",
       " 'PPFP_FCFP_0750',\n",
       " 'PPFP_FCFP_0751',\n",
       " 'PPFP_FCFP_0752',\n",
       " 'PPFP_FCFP_0753',\n",
       " 'PPFP_FCFP_0754',\n",
       " 'PPFP_FCFP_0755',\n",
       " 'PPFP_FCFP_0756',\n",
       " 'PPFP_FCFP_0757',\n",
       " 'PPFP_FCFP_0758',\n",
       " 'PPFP_FCFP_0759',\n",
       " 'PPFP_FCFP_0760',\n",
       " 'PPFP_FCFP_0761',\n",
       " 'PPFP_FCFP_0762',\n",
       " 'PPFP_FCFP_0763',\n",
       " 'PPFP_FCFP_0764',\n",
       " 'PPFP_FCFP_0765',\n",
       " 'PPFP_FCFP_0766',\n",
       " 'PPFP_FCFP_0767',\n",
       " 'PPFP_FCFP_0768',\n",
       " 'PPFP_FCFP_0769',\n",
       " 'PPFP_FCFP_0770',\n",
       " 'PPFP_FCFP_0771',\n",
       " 'PPFP_FCFP_0772',\n",
       " 'PPFP_FCFP_0773',\n",
       " 'PPFP_FCFP_0774',\n",
       " 'PPFP_FCFP_0775',\n",
       " 'PPFP_FCFP_0776',\n",
       " 'PPFP_FCFP_0777',\n",
       " 'PPFP_FCFP_0778',\n",
       " 'PPFP_FCFP_0779',\n",
       " 'PPFP_FCFP_0780',\n",
       " 'PPFP_FCFP_0781',\n",
       " 'PPFP_FCFP_0782',\n",
       " 'PPFP_FCFP_0783',\n",
       " 'PPFP_FCFP_0784',\n",
       " 'PPFP_FCFP_0785',\n",
       " 'PPFP_FCFP_0786',\n",
       " 'PPFP_FCFP_0787',\n",
       " 'PPFP_FCFP_0788',\n",
       " 'PPFP_FCFP_0789',\n",
       " 'PPFP_FCFP_0790',\n",
       " 'PPFP_FCFP_0791',\n",
       " 'PPFP_FCFP_0792',\n",
       " 'PPFP_FCFP_0793',\n",
       " 'PPFP_FCFP_0794',\n",
       " 'PPFP_FCFP_0795',\n",
       " 'PPFP_FCFP_0796',\n",
       " 'PPFP_FCFP_0797',\n",
       " 'PPFP_FCFP_0798',\n",
       " 'PPFP_FCFP_0799',\n",
       " 'PPFP_FCFP_0800',\n",
       " 'PPFP_FCFP_0801',\n",
       " 'PPFP_FCFP_0802',\n",
       " 'PPFP_FCFP_0803',\n",
       " 'PPFP_FCFP_0804',\n",
       " 'PPFP_FCFP_0805',\n",
       " 'PPFP_FCFP_0806',\n",
       " 'PPFP_FCFP_0807',\n",
       " 'PPFP_FCFP_0808',\n",
       " 'PPFP_FCFP_0809',\n",
       " 'PPFP_FCFP_0810',\n",
       " 'PPFP_FCFP_0811',\n",
       " 'PPFP_FCFP_0812',\n",
       " 'PPFP_FCFP_0813',\n",
       " 'PPFP_FCFP_0814',\n",
       " 'PPFP_FCFP_0815',\n",
       " 'PPFP_FCFP_0816',\n",
       " 'PPFP_FCFP_0817',\n",
       " 'PPFP_FCFP_0818',\n",
       " 'PPFP_FCFP_0819',\n",
       " 'PPFP_FCFP_0820',\n",
       " 'PPFP_FCFP_0821',\n",
       " 'PPFP_FCFP_0822',\n",
       " 'PPFP_FCFP_0823',\n",
       " 'PPFP_FCFP_0824',\n",
       " 'PPFP_FCFP_0825',\n",
       " 'PPFP_FCFP_0826',\n",
       " 'PPFP_FCFP_0827',\n",
       " 'PPFP_FCFP_0828',\n",
       " 'PPFP_FCFP_0829',\n",
       " 'PPFP_FCFP_0830',\n",
       " 'PPFP_FCFP_0831',\n",
       " 'PPFP_FCFP_0832',\n",
       " 'PPFP_FCFP_0833',\n",
       " 'PPFP_FCFP_0834',\n",
       " 'PPFP_FCFP_0835',\n",
       " 'PPFP_FCFP_0836',\n",
       " 'PPFP_FCFP_0837',\n",
       " 'PPFP_FCFP_0838',\n",
       " 'PPFP_FCFP_0839',\n",
       " 'PPFP_FCFP_0840',\n",
       " 'PPFP_FCFP_0841',\n",
       " 'PPFP_FCFP_0842',\n",
       " 'PPFP_FCFP_0843',\n",
       " 'PPFP_FCFP_0844',\n",
       " 'PPFP_FCFP_0845',\n",
       " 'PPFP_FCFP_0846',\n",
       " 'PPFP_FCFP_0847',\n",
       " 'PPFP_FCFP_0848',\n",
       " 'PPFP_FCFP_0849',\n",
       " 'PPFP_FCFP_0850',\n",
       " 'PPFP_FCFP_0851',\n",
       " 'PPFP_FCFP_0852',\n",
       " 'PPFP_FCFP_0853',\n",
       " 'PPFP_FCFP_0854',\n",
       " 'PPFP_FCFP_0855',\n",
       " 'PPFP_FCFP_0856',\n",
       " 'PPFP_FCFP_0857',\n",
       " 'PPFP_FCFP_0858',\n",
       " 'PPFP_FCFP_0859',\n",
       " 'PPFP_FCFP_0860',\n",
       " 'PPFP_FCFP_0861',\n",
       " 'PPFP_FCFP_0862',\n",
       " 'PPFP_FCFP_0863',\n",
       " 'PPFP_FCFP_0864',\n",
       " 'PPFP_FCFP_0865',\n",
       " 'PPFP_FCFP_0866',\n",
       " 'PPFP_FCFP_0867',\n",
       " 'PPFP_FCFP_0868',\n",
       " 'PPFP_FCFP_0869',\n",
       " 'PPFP_FCFP_0870',\n",
       " 'PPFP_FCFP_0871',\n",
       " 'PPFP_FCFP_0872',\n",
       " 'PPFP_FCFP_0873',\n",
       " 'PPFP_FCFP_0874',\n",
       " 'PPFP_FCFP_0875',\n",
       " 'PPFP_FCFP_0876',\n",
       " 'PPFP_FCFP_0877',\n",
       " 'PPFP_FCFP_0878',\n",
       " 'PPFP_FCFP_0879',\n",
       " 'PPFP_FCFP_0880',\n",
       " 'PPFP_FCFP_0881',\n",
       " 'PPFP_FCFP_0882',\n",
       " 'PPFP_FCFP_0883',\n",
       " 'PPFP_FCFP_0884',\n",
       " 'PPFP_FCFP_0885',\n",
       " 'PPFP_FCFP_0886',\n",
       " 'PPFP_FCFP_0887',\n",
       " 'PPFP_FCFP_0888',\n",
       " 'PPFP_FCFP_0889',\n",
       " 'PPFP_FCFP_0890',\n",
       " 'PPFP_FCFP_0891',\n",
       " 'PPFP_FCFP_0892',\n",
       " 'PPFP_FCFP_0893',\n",
       " 'PPFP_FCFP_0894',\n",
       " 'PPFP_FCFP_0895',\n",
       " 'PPFP_FCFP_0896',\n",
       " 'PPFP_FCFP_0897',\n",
       " 'PPFP_FCFP_0898',\n",
       " 'PPFP_FCFP_0899',\n",
       " 'PPFP_FCFP_0900',\n",
       " 'PPFP_FCFP_0901',\n",
       " 'PPFP_FCFP_0902',\n",
       " 'PPFP_FCFP_0903',\n",
       " 'PPFP_FCFP_0904',\n",
       " 'PPFP_FCFP_0905',\n",
       " 'PPFP_FCFP_0906',\n",
       " 'PPFP_FCFP_0907',\n",
       " 'PPFP_FCFP_0908',\n",
       " 'PPFP_FCFP_0909',\n",
       " 'PPFP_FCFP_0910',\n",
       " 'PPFP_FCFP_0911',\n",
       " 'PPFP_FCFP_0912',\n",
       " 'PPFP_FCFP_0913',\n",
       " 'PPFP_FCFP_0914',\n",
       " 'PPFP_FCFP_0915',\n",
       " 'PPFP_FCFP_0916',\n",
       " 'PPFP_FCFP_0917',\n",
       " 'PPFP_FCFP_0918',\n",
       " 'PPFP_FCFP_0919',\n",
       " 'PPFP_FCFP_0920',\n",
       " 'PPFP_FCFP_0921',\n",
       " 'PPFP_FCFP_0922',\n",
       " 'PPFP_FCFP_0923',\n",
       " 'PPFP_FCFP_0924',\n",
       " 'PPFP_FCFP_0925',\n",
       " 'PPFP_FCFP_0926',\n",
       " 'PPFP_FCFP_0927',\n",
       " 'PPFP_FCFP_0928',\n",
       " 'PPFP_FCFP_0929',\n",
       " 'PPFP_FCFP_0930',\n",
       " 'PPFP_FCFP_0931',\n",
       " 'PPFP_FCFP_0932',\n",
       " 'PPFP_FCFP_0933',\n",
       " 'PPFP_FCFP_0934',\n",
       " 'PPFP_FCFP_0935',\n",
       " 'PPFP_FCFP_0936',\n",
       " 'PPFP_FCFP_0937',\n",
       " 'PPFP_FCFP_0938',\n",
       " 'PPFP_FCFP_0939',\n",
       " 'PPFP_FCFP_0940',\n",
       " 'PPFP_FCFP_0941',\n",
       " 'PPFP_FCFP_0942',\n",
       " 'PPFP_FCFP_0943',\n",
       " 'PPFP_FCFP_0944',\n",
       " 'PPFP_FCFP_0945',\n",
       " 'PPFP_FCFP_0946',\n",
       " 'PPFP_FCFP_0947',\n",
       " 'PPFP_FCFP_0948',\n",
       " 'PPFP_FCFP_0949',\n",
       " 'PPFP_FCFP_0950',\n",
       " 'PPFP_FCFP_0951',\n",
       " 'PPFP_FCFP_0952',\n",
       " 'PPFP_FCFP_0953',\n",
       " 'PPFP_FCFP_0954',\n",
       " 'PPFP_FCFP_0955',\n",
       " 'PPFP_FCFP_0956',\n",
       " 'PPFP_FCFP_0957',\n",
       " 'PPFP_FCFP_0958',\n",
       " 'PPFP_FCFP_0959',\n",
       " 'PPFP_FCFP_0960',\n",
       " 'PPFP_FCFP_0961',\n",
       " 'PPFP_FCFP_0962',\n",
       " 'PPFP_FCFP_0963',\n",
       " 'PPFP_FCFP_0964',\n",
       " 'PPFP_FCFP_0965',\n",
       " 'PPFP_FCFP_0966',\n",
       " 'PPFP_FCFP_0967',\n",
       " 'PPFP_FCFP_0968',\n",
       " 'PPFP_FCFP_0969',\n",
       " 'PPFP_FCFP_0970',\n",
       " 'PPFP_FCFP_0971',\n",
       " 'PPFP_FCFP_0972',\n",
       " 'PPFP_FCFP_0973',\n",
       " 'PPFP_FCFP_0974',\n",
       " 'PPFP_FCFP_0975',\n",
       " 'PPFP_FCFP_0976',\n",
       " 'PPFP_FCFP_0977',\n",
       " 'PPFP_FCFP_0978',\n",
       " 'PPFP_FCFP_0979',\n",
       " 'PPFP_FCFP_0980',\n",
       " 'PPFP_FCFP_0981',\n",
       " 'PPFP_FCFP_0982',\n",
       " 'PPFP_FCFP_0983',\n",
       " 'PPFP_FCFP_0984',\n",
       " 'PPFP_FCFP_0985',\n",
       " 'PPFP_FCFP_0986',\n",
       " 'PPFP_FCFP_0987',\n",
       " 'PPFP_FCFP_0988',\n",
       " 'PPFP_FCFP_0989',\n",
       " 'PPFP_FCFP_0990',\n",
       " 'PPFP_FCFP_0991',\n",
       " 'PPFP_FCFP_0992',\n",
       " 'PPFP_FCFP_0993',\n",
       " 'PPFP_FCFP_0994',\n",
       " 'PPFP_FCFP_0995',\n",
       " 'PPFP_FCFP_0996',\n",
       " 'PPFP_FCFP_0997',\n",
       " 'PPFP_FCFP_0998',\n",
       " 'PPFP_FCFP_0999',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pipe_FP=pd.read_csv('caco_PipelinePilot_FP.tsv', sep='\\t', index_col=False)\n",
    "list(df_pipe_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule', 'Class']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out=pd.read_csv('caco_Outcome.tsv', sep='\\t', index_col=False)\n",
    "list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_df=df_dragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 52)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_df.drop(x_df.columns[[1]], axis=1)\n",
    "#x_df\n",
    "x_df.set_index('Molecule', inplace=True)\n",
    "x_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXAiSZI6xXAiSZI65f8HdoPDD67T+RcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f9c6110b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA().fit(x_df)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"variance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=5)\n",
    "x_pca=pca.fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df=df_out\n",
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class\n",
       "0     M\n",
       "1     L\n",
       "2     M\n",
       "3     M\n",
       "4     M"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final=y_df.drop('Molecule', axis=1)\n",
    "y_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df=train_test_split(x_pca, y_final, test_size=0.2)\n",
    "#x_train_int=table.Columns.RemoveAt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler=StandardScaler()\n",
    "clf_model=x_scaler.fit(x_train_df)\n",
    "x_train_norm=clf_model.transform(x_train_df)\n",
    "x_test_norm=clf_model.transform(x_test_df)\n",
    "x_train_norm.shape, x_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3036, 3), (760, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoder=LabelEncoder()\n",
    "y_encoded_tr=y_encoder.fit_transform(y_train_df)\n",
    "y_enc_tr=np_utils.to_categorical(y_encoded_tr)\n",
    "y_enc_tr.shape\n",
    "y_encoded_test=y_encoder.fit_transform(y_test_df)\n",
    "y_enc_test=np_utils.to_categorical(y_encoded_test)\n",
    "y_enc_tr.shape,y_enc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc_tr.shape[0], y_enc_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler=StandardScaler()\n",
    "y_train_norm=y_scaler.fit_transform(y_enc_tr)\n",
    "y_test_norm=y_scaler.transform(y_enc_test)\n",
    "y_train_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5, input_dim=5,init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(75, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(25, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))   \n",
    "    #model.add(Dense(12, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", input_dim=5, activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 47.0424046153\n"
     ]
    }
   ],
   "source": [
    "#fit and evaluate the model\n",
    "estimators=[]\n",
    "#estimators.append(('standardise',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=200, verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results=cross_val_score(pipeline, x_train_norm, y_train_norm, cv=kfold)\n",
    "print('accuracy:', results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5), (3036, 3), (760, 3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape, x_test_norm.shape, y_train_norm.shape, y_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final, y_test_final=train_test_split(y_final, test_size=0.2)\n",
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.539473684211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_linear=linear_model.LogisticRegression()\n",
    "model_linear=clf_linear.fit(x_train_norm, y_train_final)\n",
    "acc_logit=model_linear.score(x_test_norm, y_test_final)\n",
    "print('accuracy:',acc_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.492105263158\n"
     ]
    }
   ],
   "source": [
    "tree_c=DecisionTreeClassifier(random_state=seed)#check this\n",
    "model_c=tree_c.fit(x_train_norm, y_train_final)\n",
    "acc_clf=model_c.score(x_test_norm, y_test_final)\n",
    "print('accuracy:', acc_clf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_c, out_file='tree_clf.dot', rounded=True)#visualizing the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SGD: 0.315789473684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_SGD=linear_model.SGDClassifier(loss='epsilon_insensitive', penalty='none', alpha=0.0001)\n",
    "clf_SGD.fit(x_train_norm, y_train_final)\n",
    "y_predict_SGD=clf_SGD.predict(x_test_norm)\n",
    "acc_SGD=clf_SGD.score(x_test_norm, y_test_final)\n",
    "print('accuracy of SGD:', acc_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of svc: 0.519736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc=SVC(kernel='rbf', C=1e3)\n",
    "clf_svc.fit(x_train_norm, y_train_final)\n",
    "y_predict_svc=clf_svc.predict(x_test_norm)\n",
    "acc_svc=clf_svc.score(x_test_norm, y_test_final)\n",
    "print(\"accuracy of svc:\", acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of randomforest: 0.494736842105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train_norm, y_train_final)\n",
    "rf_predict_norm=rf.predict(x_test_norm)\n",
    "acc_rf=rf.score(x_test_norm, y_test_final)\n",
    "print('accuracy of randomforest:', acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary class modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(df_dragon), list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dragon_mrg=pd.merge(df_quick, df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_dragon_mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HM model\n",
    "a=df_dragon_mrg[df_out['Class']=='H']\n",
    "b=df_dragon_mrg[df_out['Class']=='M']\n",
    "frames_hm=[a, b]\n",
    "HM=pd.concat(frames_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ML model\n",
    "c=df_dragon_mrg[df_out['Class']=='M']\n",
    "d=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_ml=[c,d]\n",
    "ML=pd.concat(frames_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2406, 53)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 2, 0, ..., 7, 38, 1],\n",
       "       [0, 2, 0, ..., 8, 39, 1],\n",
       "       ..., \n",
       "       [19, 1, 1, ..., 4, 72, 2],\n",
       "       [0, 0, 0, ..., 4, 19, 0],\n",
       "       [0, 1, 0, ..., 4, 24, 0]], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ML=ML.values[:, 1:51]\n",
    "x_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', ..., 'L', 'L', 'L'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ML=ML.values[:, 52]\n",
    "y_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_x_train, ML_x_test, ML_y_train, ML_y_test = train_test_split(x_ML, y_ML, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HL model\n",
    "e=df_dragon_mrg[df_out['Class']=='H']\n",
    "f=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_hl=[e,f]\n",
    "HL=pd.concat(frames_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1767, 53)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_HL=HL.values[:,1:51]\n",
    "y_HL=HL.values[:, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HL_x_train, HL_x_test, HL_y_train, HL_y_test=train_test_split(x_HL, y_HL, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.   0.   0. ...,   0.  11.   0.]\n",
      " [  0.   0.   0. ...,   0.  11.   0.]\n",
      " [  1.   1.   0. ...,   9.  41.   0.]\n",
      " ..., \n",
      " [  0.   0.   0. ...,   7.  23.   0.]\n",
      " [  0.   1.   0. ...,   5.  28.   0.]\n",
      " [  0.   1.   0. ...,   2.  21.   0.]]\n"
     ]
    }
   ],
   "source": [
    "x_HM=HM.values[:, 1:51].astype('float32')\n",
    "print(x_HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'H', 'H', ..., 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_HM=HM.values[:, 52]\n",
    "y_HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HM_x_train, HM_x_test, HM_y_train, HM_y_test=train_test_split(x_HM,y_HM, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2735, 50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HM_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Decision tree model for HM class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.18093385  0.81906615]\n",
      " [ 0.6547619   0.3452381 ]\n",
      " [ 0.0104712   0.9895288 ]\n",
      " ..., \n",
      " [ 0.18093385  0.81906615]\n",
      " [ 0.96606335  0.03393665]\n",
      " [ 0.12078652  0.87921348]]\n",
      "accuracy for HM model: 0.818713450292\n"
     ]
    }
   ],
   "source": [
    "tree_hm=DecisionTreeClassifier(min_weight_fraction_leaf=0.13, max_leaf_nodes=12)\n",
    "tree_hm.fit(HM_x_train, HM_y_train)\n",
    "acc_hm=tree_hm.score(HM_x_test, HM_y_test)\n",
    "\n",
    "print(tree_hm.classes_)\n",
    "print(tree_hm.predict_proba(HM_x_test))\n",
    "print('accuracy for HM model:',acc_hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chiad tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CHAID import Tree\n",
    "\n",
    "#CHAID input parameters\n",
    "indep_variable_cols=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW']\n",
    "dep_variable=[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip(indep_variable_cols,['nominal']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tree from pandas\n",
    "tree_chaid= Tree.from_pandas_df(HM, dict(zip(indep_variable_cols, ['nominal']*3)), dep_variable, \n",
    "                          max_depth=4, min_parent_node_size=80, min_child_node_size=35)\n",
    "#tree.to_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest classifier for HM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "accuracy of Random forest for HM model is: 0.963450292398\n",
      "mcc: 0.921785168286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=95, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm=RandomForestClassifier(n_estimators=95, random_state=1)\n",
    "RF_hm.fit(HM_x_train, HM_y_train)\n",
    "RF_hm_predict= RF_hm.predict(HM_x_test)\n",
    "acc_RF_HM=RF_hm.score(HM_x_test, HM_y_test)\n",
    "\n",
    "print(RF_hm.classes_)\n",
    "print(RF_hm.predict_proba(HM_x_test))\n",
    "print('accuracy of Random forest for HM model is:', acc_RF_HM)\n",
    "\n",
    "\n",
    "#matthews correlation coefficient\n",
    "matt_corr=matthews_corrcoef(HM_y_test, RF_hm_predict)\n",
    "print('mcc:',matt_corr)\n",
    "\n",
    "RF_hm.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.05, presort=False,\n",
      "            random_state=None, splitter='best')>\n",
      "accuracy for the CT for ML model: 0.933609958506\n",
      "probability predictions for ML model: [[ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.99130435  0.00869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.29245283  0.70754717]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07246377  0.92753623]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.          1.        ]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.75675676  0.24324324]\n",
      " [ 0.01010101  0.98989899]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02877698  0.97122302]\n",
      " [ 0.11976048  0.88023952]\n",
      " [ 0.37735849  0.62264151]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tree_ml=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_ml.fit(ML_x_train, ML_y_train)\n",
    "acc_tree_ml=tree_ml.score(ML_x_test, ML_y_test)\n",
    "pre_tree_ml=tree_ml.predict_proba(ML_x_test)\n",
    "\n",
    "print('order of classes:',tree_ml.classes_)\n",
    "print(tree_ml.get_params)\n",
    "print('accuracy for the CT for ML model:', acc_tree_ml)\n",
    "print('probability predictions for ML model:', pre_tree_ml)\n",
    "#len(acc_tree_ml),len(ML_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "accuracy of model: 0.9377593361\n",
      "probabilities of the respective classes: [[ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.19565217  0.80434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.          1.        ]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 1.          0.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.23188406  0.76811594]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73913043  0.26086957]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.7826087   0.2173913 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73913043  0.26086957]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.19565217  0.80434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.7826087   0.2173913 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73913043  0.26086957]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.23913043  0.76086957]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.19565217  0.80434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.15217391  0.84782609]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]]\n",
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=23, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "RF_ml=RandomForestClassifier(n_estimators=23, random_state=2)\n",
    "RF_ml.fit(ML_x_train, ML_y_train)\n",
    "accu_RF_ml=RF_ml.score(ML_x_test, ML_y_test)\n",
    "pre_RF_ml=RF_ml.predict_proba(ML_x_test)\n",
    "\n",
    "print('order of classes:',RF_ml.classes_)\n",
    "print('accuracy of model:', accu_RF_ml)\n",
    "print('probabilities of the respective classes:', pre_RF_ml)\n",
    "print(RF_ml.get_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree for the LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of the model 0.949152542373\n",
      "probabilities of the classes: [[ 0.75        0.25      ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.05633803  0.94366197]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85393258  0.14606742]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 0.37179487  0.62820513]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98347107  0.01652893]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]]\n",
      "prediction of classes: ['H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L'\n",
      " 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'L' 'H' 'L' 'L' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'L' 'L' 'H'\n",
      " 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.05, presort=False,\n",
       "            random_state=None, splitter='best')>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_LH=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_tree_LH=tree_LH.score(HL_x_test, HL_y_test)\n",
    "predict_tree_LH=tree_LH.predict(HL_x_test)\n",
    "prob_tree_LH=tree_LH.predict_proba(HL_x_test)\n",
    "\n",
    "print('order of classes:', tree_LH.classes_)\n",
    "print(\"accuracy of the model\", acc_tree_LH)\n",
    "print('probabilities of the classes:', prob_tree_LH)\n",
    "print('prediction of classes:', predict_tree_LH)\n",
    "\n",
    "tree_LH.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest for LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of model: 0.977401129944\n",
      "probabilities of the respective classes: [[ 0.93617021  0.06382979]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.70212766  0.29787234]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.17375887  0.82624113]\n",
      " [ 0.59574468  0.40425532]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.68085106  0.31914894]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.72340426  0.27659574]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.14893617  0.85106383]\n",
      " [ 1.          0.        ]\n",
      " [ 0.38297872  0.61702128]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08510638  0.91489362]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.91489362  0.08510638]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10638298  0.89361702]\n",
      " [ 0.21276596  0.78723404]\n",
      " [ 0.31914894  0.68085106]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.12765957  0.87234043]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.40425532  0.59574468]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.59574468  0.40425532]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.25531915  0.74468085]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 0.70212766  0.29787234]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10638298  0.89361702]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.38297872  0.61702128]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.72340426  0.27659574]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.21276596  0.78723404]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 0.31914894  0.68085106]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.34042553  0.65957447]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25531915  0.74468085]\n",
      " [ 0.27659574  0.72340426]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.14893617  0.85106383]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.12765957  0.87234043]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82978723  0.17021277]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5106383   0.4893617 ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]]\n",
      "predictions of the model: ['H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L'\n",
      " 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'L' 'L' 'H'\n",
      " 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'L' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H']\n"
     ]
    }
   ],
   "source": [
    "RF_LH=RandomForestClassifier(n_estimators=47, random_state=3)\n",
    "RF_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_RF_HL=RF_LH.score(HL_x_test, HL_y_test)\n",
    "predict_RF_HL=RF_LH.predict(HL_x_test)\n",
    "pro_RF_HL=RF_LH.predict_proba(HL_x_test)\n",
    "\n",
    "print('order of classes:', RF_LH.classes_)\n",
    "print('accuracy of model:', acc_RF_HL)\n",
    "print('probabilities of the respective classes:', pro_RF_HL)\n",
    "print('predictions of the model:', predict_RF_HL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
