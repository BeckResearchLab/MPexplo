{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import r2_score, matthews_corrcoef\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 997)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atom=pd.read_csv('caco_AtomPair.tsv', sep='\\t', index_col=False)\n",
    "df_atom.shape\n",
    "#df_atom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 53)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dragon=pd.read_csv('caco_Dragon.tsv', sep='\\t', index_col=False)\n",
    "df_dragon.shape\n",
    "#pd.DataFrame.to_csv(df_dragon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 52)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quick=pd.read_csv('caco_QuickProp.tsv', sep='\\t', index_col=False)\n",
    "df_quick.shape\n",
    "#list(df_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 5402)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pipe_FP=pd.read_csv('caco_PipelinePilot_FP.tsv', sep='\\t', index_col=False)\n",
    "df_pipe_FP.shape\n",
    "#list(df_pipe_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule', 'Class']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out=pd.read_csv('caco_Outcome.tsv', sep='\\t', index_col=False)\n",
    "list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_df=df_dragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 52)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_df.drop(x_df.columns[[1]], axis=1)\n",
    "#x_df\n",
    "x_df.set_index('Molecule', inplace=True)\n",
    "x_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXAiSZI6xXAiSZI65f8HdoPDD67T+RcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e235291eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA().fit(x_df)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"variance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=5)\n",
    "x_pca=pca.fit_transform(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df=df_out\n",
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class\n",
       "0     M\n",
       "1     L\n",
       "2     M\n",
       "3     M\n",
       "4     M"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final=y_df.drop('Molecule', axis=1)\n",
    "y_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df=train_test_split(x_pca, y_final, test_size=0.2)\n",
    "#x_train_int=table.Columns.RemoveAt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler=StandardScaler()\n",
    "clf_model=x_scaler.fit(x_train_df)\n",
    "x_train_norm=clf_model.transform(x_train_df)\n",
    "x_test_norm=clf_model.transform(x_test_df)\n",
    "x_train_norm.shape, x_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3036, 3), (760, 3))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoder=LabelEncoder()\n",
    "y_encoded_tr=y_encoder.fit_transform(y_train_df)\n",
    "y_enc_tr=np_utils.to_categorical(y_encoded_tr)\n",
    "y_enc_tr.shape\n",
    "y_encoded_test=y_encoder.fit_transform(y_test_df)\n",
    "y_enc_test=np_utils.to_categorical(y_encoded_test)\n",
    "y_enc_tr.shape,y_enc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc_tr.shape[0], y_enc_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler=StandardScaler()\n",
    "y_scaler.fit(y_enc_tr)\n",
    "y_train_norm=y_scaler.transform(y_enc_tr)\n",
    "y_test_norm=y_scaler.transform(y_enc_test)\n",
    "y_train_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5, input_dim=5,init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(75, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(25, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))   \n",
    "    #model.add(Dense(12, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"normal\", activation=\"relu\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 40.7729719227\n"
     ]
    }
   ],
   "source": [
    "#fit and evaluate the model\n",
    "estimators=[]\n",
    "#estimators.append(('standardise',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=200, verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results=cross_val_score(pipeline, x_train_norm, y_train_norm, cv=kfold)\n",
    "print('accuracy:', results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5), (3036, 3), (760, 3))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape, x_test_norm.shape, y_train_norm.shape, y_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final, y_test_final=train_test_split(y_final, test_size=0.2)\n",
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.518421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_linear=linear_model.LogisticRegression()\n",
    "model_linear=clf_linear.fit(x_train_norm, y_train_final)\n",
    "acc_logit=model_linear.score(x_test_norm, y_test_final)\n",
    "print('accuracy:',acc_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation of the confusion matrix for Logistic\n",
    "clf_logit_predict=clf_linear.predict(x_test_norm)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_final, clf_logit_predict)\n",
    "\n",
    "cmatrix_logit=confusion_matrix(y_test_final, clf_logit_predict)\n",
    "cmatrix_logit.diagonal()/cmatrix_logit.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.477631578947\n"
     ]
    }
   ],
   "source": [
    "tree_c=DecisionTreeClassifier(random_state=seed)#check this\n",
    "model_c=tree_c.fit(x_train_norm, y_train_final)\n",
    "acc_clf=model_c.score(x_test_norm, y_test_final)\n",
    "print('accuracy:', acc_clf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_c, out_file='tree_clf.dot', rounded=True)#visualizing the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SGD: 0.457894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_SGD=linear_model.SGDClassifier(loss='epsilon_insensitive', penalty='none', alpha=0.0001)\n",
    "clf_SGD.fit(x_train_norm, y_train_final)\n",
    "y_predict_SGD=clf_SGD.predict(x_test_norm)\n",
    "acc_SGD=clf_SGD.score(x_test_norm, y_test_final)\n",
    "print('accuracy of SGD:', acc_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of svc: 0.507894736842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc=SVC(kernel='rbf', C=1e3)\n",
    "clf_svc.fit(x_train_norm, y_train_final)\n",
    "y_predict_svc=clf_svc.predict(x_test_norm)\n",
    "acc_svc=clf_svc.score(x_test_norm, y_test_final)\n",
    "print(\"accuracy of svc:\", acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of randomforest: 0.498684210526\n",
      "order of classes ['H' 'L' 'M']\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=70)\n",
    "rf.fit(x_train_norm, y_train_final)\n",
    "rf_predict_norm=rf.predict(x_test_norm)\n",
    "acc_rf=rf.score(x_test_norm, y_test_final)\n",
    "print('accuracy of randomforest:', acc_rf)\n",
    "print('order of classes', rf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 57,   2, 230],\n",
       "       [ 15,   1,  61],\n",
       "       [ 69,   4, 321]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the confusion matrix\n",
    "confusion_matrix(y_test_final, rf_predict_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19723183,  0.01298701,  0.81472081])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf=confusion_matrix(y_test_final, rf_predict_norm)\n",
    "cmatrix_rf.diagonal()/cmatrix_rf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary class modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(df_dragon), list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dragon_mrg=pd.merge(df_quick, df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_dragon_mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HM model\n",
    "a=df_dragon_mrg[df_out['Class']=='H']\n",
    "b=df_dragon_mrg[df_out['Class']=='M']\n",
    "frames_hm=[a, b]\n",
    "HM=pd.concat(frames_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ML model\n",
    "c=df_dragon_mrg[df_out['Class']=='M']\n",
    "d=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_ml=[c,d]\n",
    "ML=pd.concat(frames_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2406, 53)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 2, 0, ..., 7, 38, 1],\n",
       "       [0, 2, 0, ..., 8, 39, 1],\n",
       "       ..., \n",
       "       [19, 1, 1, ..., 4, 72, 2],\n",
       "       [0, 0, 0, ..., 4, 19, 0],\n",
       "       [0, 1, 0, ..., 4, 24, 0]], dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ML=ML.values[:, 1:51]\n",
    "x_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', ..., 'L', 'L', 'L'], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ML=ML.values[:, 52]\n",
    "y_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_x_train, ML_x_test, ML_y_train, ML_y_test = train_test_split(x_ML, y_ML, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HL model\n",
    "e=df_dragon_mrg[df_out['Class']=='H']\n",
    "f=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_hl=[e,f]\n",
    "HL=pd.concat(frames_hl)\n",
    "#HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1767, 53)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_HL=HL.values[:,1:51]\n",
    "y_HL=HL.values[:, 52]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HL_x_train, HL_x_test, HL_y_train, HL_y_test=train_test_split(x_HL, y_HL, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.   0.   0. ...,   0.  11.   0.]\n",
      " [  0.   0.   0. ...,   0.  11.   0.]\n",
      " [  1.   1.   0. ...,   9.  41.   0.]\n",
      " ..., \n",
      " [  0.   0.   0. ...,   7.  23.   0.]\n",
      " [  0.   1.   0. ...,   5.  28.   0.]\n",
      " [  0.   1.   0. ...,   2.  21.   0.]]\n"
     ]
    }
   ],
   "source": [
    "x_HM=HM.values[:, 1:51].astype('float32')\n",
    "print(x_HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'H', 'H', ..., 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_HM=HM.values[:, 52]\n",
    "y_HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HM_x_train, HM_x_test, HM_y_train, HM_y_test=train_test_split(x_HM,y_HM, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Decision tree model for HM class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.0848329   0.9151671 ]\n",
      " [ 0.0848329   0.9151671 ]\n",
      " [ 0.88282504  0.11717496]\n",
      " ..., \n",
      " [ 0.0848329   0.9151671 ]\n",
      " [ 0.34624697  0.65375303]\n",
      " [ 0.88282504  0.11717496]]\n",
      "accuracy for HM model: 0.880116959064\n",
      "mcc for the CART for HM: 0.743578882513\n"
     ]
    }
   ],
   "source": [
    "tree_hm=DecisionTreeClassifier(min_weight_fraction_leaf=0.13, max_leaf_nodes=12)\n",
    "tree_hm.fit(HM_x_train, HM_y_train)\n",
    "acc_hm=tree_hm.score(HM_x_test, HM_y_test)\n",
    "tree_hm_predict=tree_hm.predict(HM_x_test)\n",
    "\n",
    "#matthews correlation coefficient\n",
    "matt_tree_hm=matthews_corrcoef(HM_y_test, tree_hm_predict)\n",
    "\n",
    "print(tree_hm.classes_)\n",
    "print(tree_hm.predict_proba(HM_x_test))\n",
    "print('accuracy for HM model:',acc_hm)\n",
    "print('mcc for the CART for HM:', matt_tree_hm)\n",
    "#mcc of the literature value for only the CART model is 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37390871055829272, 0.62609128944170733)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=tree_hm.predict_proba(HM_x_test)\n",
    "z[:,0].mean(), z[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[206,  55],\n",
       "       [ 27, 396]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for tree in HM\n",
    "confusion_matrix(HM_y_test, tree_hm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78927203,  0.93617021])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_tree_hm=confusion_matrix(HM_y_test, tree_hm_predict)\n",
    "cmatrix_tree_hm.diagonal()/cmatrix_tree_hm.sum(axis=1)\n",
    "#LITERATURE VALUE OF THE CONSENSUS MODEL\n",
    "#H:0.78\n",
    "#M:0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting the receiver operating characteristic curve\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "roc_auc=dict()\n",
    "HM_y_test_col=HM_y_test[:,None]\n",
    "tree_hm_predict_col=tree_hm_predict[:,None]\n",
    "#y_tree_ml=tree_hm.fit(HM_x_train, HM_y_train)\n",
    "for i in range(0,1):\n",
    "    fpr[i], tpr[i], _=roc_curve(label_binarize(HM_y_test_col[:,i], classes=['H', 'M']),\n",
    "                                label_binarize(tree_hm_predict_col[:,i], classes=['H','M']))\n",
    "    roc_auc[i]=auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4wxxoSdBSDGGGOMCbv/D4K1HccHFBTQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e227952358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange', lw=lw, label='ROC curve(area=%f)' % roc_auc[0])\n",
    "plt.plot([0,1.0], [0, 1.0], color='blue', linestyle='--')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for CART for HM')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chiad tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CHAID import Tree\n",
    "\n",
    "#CHAID input parameters\n",
    "indep_variable_cols=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW']\n",
    "dep_variable=[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip(indep_variable_cols,['nominal']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tree from pandas\n",
    "tree_chaid= Tree.from_pandas_df(HM, dict(zip(indep_variable_cols, ['nominal']*3)), dep_variable, \n",
    "                          max_depth=4, min_parent_node_size=80, min_child_node_size=35)\n",
    "#tree.to_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest classifier for HM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.          1.        ]\n",
      " [ 0.10526316  0.89473684]\n",
      " [ 1.          0.        ]\n",
      " ..., \n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]]\n",
      "accuracy of Random forest for HM model is: 0.941520467836\n",
      "mcc: 0.875831383053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=95, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm=RandomForestClassifier(n_estimators=95, random_state=1)\n",
    "RF_hm.fit(HM_x_train, HM_y_train)\n",
    "RF_hm_predict= RF_hm.predict(HM_x_test)\n",
    "acc_RF_HM=RF_hm.score(HM_x_test, HM_y_test)\n",
    "\n",
    "print(RF_hm.classes_)\n",
    "print(RF_hm.predict_proba(HM_x_test))\n",
    "print('accuracy of Random forest for HM model is:', acc_RF_HM)\n",
    "\n",
    "\n",
    "#matthews correlation coefficient\n",
    "matt_corr_HM=matthews_corrcoef(HM_y_test, RF_hm_predict)\n",
    "print('mcc:',matt_corr_HM)\n",
    "\n",
    "RF_hm.get_params\n",
    "\n",
    "#MCC OF THE LITERATURE VALUE FOR THE HM RF IS 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[232,  29],\n",
       "       [ 11, 412]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(HM_y_test, RF_hm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88888889,  0.97399527])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_hm=confusion_matrix(HM_y_test, RF_hm_predict)\n",
    "cmatrix_rf_hm.diagonal()/cmatrix_rf_hm.sum(axis=1)\n",
    "#LITERATURE VALUE FOR consensus model\n",
    "#H:0.78\n",
    "#M:0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RF_hm_predict, HM_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(y_HM, classes=['H', 'M'])\n",
    "n_classes=y.shape[1]\n",
    "#roc\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "roc_auc=dict()\n",
    "HM_y_test_col=HM_y_test[:, None]\n",
    "RF_hm_predict_col=RF_hm_predict[:,None]\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _= roc_curve(label_binarize(HM_y_test_col[:,i], classes=['H','M']), \n",
    "                                 label_binarize(RF_hm_predict_col[:,i], classes=['H','M']))\n",
    "    roc_auc[i]= auc(fpr[i], tpr[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt10AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e2279b7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the ROC curve\n",
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange', lw=lw, label='ROC curve (area=%f)' % roc_auc[0])\n",
    "plt.plot([0,1],[0,1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for RF for HM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,   8,  45],\n",
       "       [  5,   0,   4],\n",
       "       [258,  69, 345]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation of confustion matrix\n",
    "confusion_matrix(y_predict_svc, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm_predict_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NN FOR CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((684, 2), (2735, 2))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "y_encoder=LabelEncoder()\n",
    "y_encoded_tr_HM=y_encoder.fit_transform(HM_y_train)\n",
    "y_en_tr_HM=np_utils.to_categorical(y_encoded_tr_HM)\n",
    "y_en_tr_HM.shape\n",
    "y_encoded_test_HM=y_encoder.fit_transform(HM_y_test)\n",
    "y_en_test_HM=np_utils.to_categorical(y_encoded_test_HM)\n",
    "y_en_test_HM.shape, y_en_tr_HM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2735, 2), (684, 2))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler=StandardScaler()\n",
    "y_scaler.fit(y_en_tr_HM)\n",
    "HM_y_train_norm=y_scaler.transform(y_en_tr_HM)\n",
    "HM_y_test_norm=y_scaler.transform(y_en_test_HM)\n",
    "HM_y_train_norm.shape, HM_y_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2735, 50), (684, 50))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HM_x_train.shape, HM_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2735, 50)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler=StandardScaler()\n",
    "x_scaler.fit(HM_x_train)\n",
    "HM_x_train_norm=x_scaler.transform(HM_x_train)\n",
    "HM_x_test_norm=x_scaler.transform(HM_x_test)\n",
    "HM_x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(51, input_dim=51, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(26, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(13, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(51, input_dim=51, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(13, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_165_input to have shape (None, 51) but got array with shape (2461, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-77343321d312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHM_x_train_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHM_y_train_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_165_input to have shape (None, 51) but got array with shape (2461, 50)"
     ]
    }
   ],
   "source": [
    "#fit and evaluate the model\n",
    "estimators=[]\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=20, verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results=cross_val_score(pipeline, HM_x_train_norm, HM_y_train_norm, cv=kfold)\n",
    "print('accuracy:', results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.05, presort=False,\n",
      "            random_state=None, splitter='best')>\n",
      "accuracy for the CT for ML model: 0.906639004149\n",
      "probability predictions for ML model: [[ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09278351  0.90721649]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04123711  0.95876289]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.15714286  0.84285714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.28971963  0.71028037]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]\n",
      " [ 0.          1.        ]\n",
      " [ 0.94957983  0.05042017]\n",
      " [ 0.          1.        ]\n",
      " [ 0.048       0.952     ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60732984  0.39267016]]\n",
      "matthews correlation coeff: 0.687209019189\n"
     ]
    }
   ],
   "source": [
    "tree_ml=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_ml.fit(ML_x_train, ML_y_train)\n",
    "acc_tree_ml=tree_ml.score(ML_x_test, ML_y_test)\n",
    "prob_tree_ml=tree_ml.predict_proba(ML_x_test)\n",
    "predict_tree_ml=tree_ml.predict(ML_x_test)\n",
    "\n",
    "print('order of classes:',tree_ml.classes_)\n",
    "print(tree_ml.get_params)\n",
    "print('accuracy for the CT for ML model:', acc_tree_ml)\n",
    "print('probability predictions for ML model:', prob_tree_ml)\n",
    "\n",
    "#matthews correlation coefficient\n",
    "mat_corr_ML=matthews_corrcoef(ML_y_test, predict_tree_ml)\n",
    "print('matthews correlation coeff:',mat_corr_ML)\n",
    "\n",
    "#len(acc_tree_ml),len(ML_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63,  13],\n",
       "       [ 32, 374]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix\n",
    "confusion_matrix(ML_y_test, predict_tree_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82894737,  0.92118227])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the accuracies of the predictions of the individual classes\n",
    "cmatrix_ML_tree=confusion_matrix(ML_y_test, predict_tree_ml)\n",
    "cmatrix_ML_tree.diagonal()/cmatrix_ML_tree.sum(axis=1)\n",
    "#literature values of L and M class respectively, ONLY FOR CART MODELS\n",
    "#L:0.83\n",
    "#M:0.70\n",
    "#literature values of L and M on the consensus system\n",
    "#L:0.79\n",
    "#M:0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "accuracy of model: 0.929460580913\n",
      "probabilities of the respective classes: [[ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.73913043  0.26086957]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91304348  0.08695652]\n",
      " [ 0.95652174  0.04347826]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.91304348  0.08695652]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91304348  0.08695652]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.91304348  0.08695652]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91304348  0.08695652]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.65217391  0.34782609]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 1.          0.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]]\n",
      "matthews correlation coefficient: 0.731664299599\n",
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=23, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "RF_ml=RandomForestClassifier(n_estimators=23, random_state=2)\n",
    "RF_ml.fit(ML_x_train, ML_y_train)\n",
    "accu_RF_ml=RF_ml.score(ML_x_test, ML_y_test)\n",
    "prob_RF_ml=RF_ml.predict_proba(ML_x_test)\n",
    "predict_RF_ml=RF_ml.predict(ML_x_test)\n",
    "#matthews correlation coefficients\n",
    "matt_coeff_ml=matthews_corrcoef(ML_y_test, predict_RF_ml)\n",
    "\n",
    "print('order of classes:',RF_ml.classes_)\n",
    "print('accuracy of model:', accu_RF_ml)\n",
    "print('probabilities of the respective classes:', prob_RF_ml)\n",
    "print('matthews correlation coefficient:', matt_coeff_ml )\n",
    "print(RF_ml.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,  18],\n",
       "       [ 16, 390]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for random forest\n",
    "confusion_matrix(ML_y_test, predict_RF_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76315789,  0.96059113])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_ml=confusion_matrix(ML_y_test, predict_RF_ml)\n",
    "cmatrix_rf_ml.diagonal()/cmatrix_rf_ml.sum(axis=1)\n",
    "\n",
    "#literature values of the consensus system for L and M classes respectively\n",
    "#L:0.79\n",
    "#M:0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree for the LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of the model 0.923728813559\n",
      "probabilities of the classes: [[ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 0.62025316  0.37974684]\n",
      " [ 0.09473684  0.90526316]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95833333  0.04166667]\n",
      " [ 0.95833333  0.04166667]]\n",
      "prediction of classes: ['H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H']\n",
      "matthews correlation coeff: 0.779530302569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.05, presort=False,\n",
       "            random_state=None, splitter='best')>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_LH=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_tree_LH=tree_LH.score(HL_x_test, HL_y_test)\n",
    "predict_tree_LH=tree_LH.predict(HL_x_test)\n",
    "prob_tree_LH=tree_LH.predict_proba(HL_x_test)\n",
    "#matthews correlation coeff\n",
    "matt_corrcoef= matthews_corrcoef(HL_y_test, predict_tree_LH)\n",
    "print('order of classes:', tree_LH.classes_)\n",
    "print(\"accuracy of the model\", acc_tree_LH)\n",
    "print('probabilities of the classes:', prob_tree_LH)\n",
    "print('prediction of classes:', predict_tree_LH)\n",
    "print('matthews correlation coeff:', matt_corrcoef)\n",
    "\n",
    "tree_LH.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265,   6],\n",
       "       [ 21,  62]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix\n",
    "confusion_matrix(HL_y_test, predict_tree_LH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97785978,  0.74698795])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_HL_tree=confusion_matrix(HL_y_test, predict_tree_LH)\n",
    "cmatrix_HL_tree.diagonal()/cmatrix_HL_tree.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest for LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of model: 0.954802259887\n",
      "probabilities of the respective classes: [[ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5106383   0.4893617 ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 0.68085106  0.31914894]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.44680851  0.55319149]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 0.          1.        ]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 0.44680851  0.55319149]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08510638  0.91489362]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91489362  0.08510638]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.40425532  0.59574468]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.80851064  0.19148936]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04255319  0.95744681]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38297872  0.61702128]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.76595745  0.23404255]\n",
      " [ 0.65957447  0.34042553]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.31914894  0.68085106]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.72340426  0.27659574]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10638298  0.89361702]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.53191489  0.46808511]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.28510638  0.71489362]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.72340426  0.27659574]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.4893617   0.5106383 ]\n",
      " [ 0.68085106  0.31914894]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10638298  0.89361702]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.59574468  0.40425532]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.29787234  0.70212766]\n",
      " [ 0.          1.        ]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 0.10638298  0.89361702]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.46808511  0.53191489]\n",
      " [ 0.          1.        ]\n",
      " [ 0.42553191  0.57446809]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.44680851  0.55319149]\n",
      " [ 0.19148936  0.80851064]\n",
      " [ 0.          1.        ]\n",
      " [ 0.70212766  0.29787234]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.91489362  0.08510638]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 0.31914894  0.68085106]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.72340426  0.27659574]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]]\n",
      "predictions of the model: ['H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'L'\n",
      " 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'L' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'L' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L'\n",
      " 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H']\n",
      "matthews correlation coefficient: 0.873142924921\n"
     ]
    }
   ],
   "source": [
    "RF_LH=RandomForestClassifier(n_estimators=47, random_state=3)\n",
    "RF_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_RF_HL=RF_LH.score(HL_x_test, HL_y_test)\n",
    "predict_RF_HL=RF_LH.predict(HL_x_test)\n",
    "prob_RF_HL=RF_LH.predict_proba(HL_x_test)\n",
    "#matthews correlation coefficient\n",
    "matt_corrcoeff_lh=matthews_corrcoef(HL_y_test, predict_RF_HL)\n",
    "\n",
    "print('order of classes:', RF_LH.classes_)\n",
    "print('accuracy of model:', acc_RF_HL)\n",
    "print('probabilities of the respective classes:', prob_RF_HL)\n",
    "print('predictions of the model:', predict_RF_HL )\n",
    "print('matthews correlation coefficient:', matt_corrcoeff_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[264,   7],\n",
       "       [  9,  74]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for HL rf\n",
    "confusion_matrix(HL_y_test, predict_RF_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97416974,  0.89156627])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_HL=confusion_matrix(HL_y_test, predict_RF_HL)\n",
    "cmatrix_rf_HL.diagonal()/cmatrix_rf_HL.sum(axis=1)\n",
    "\n",
    "#LITERATURE VALUE FOR THE LH MODEL FOR ONLY RF\n",
    "#H:0.95\n",
    "#L:0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**BUILDING A CLASSIFICATION MODEL IN TENSORFLOW FOR LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1413, 53), (354, 53))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set, test_set=train_test_split(HL, test_size=0.2)\n",
    "training_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLUMNS=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW','Class']\n",
    "FEATURES=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW']\n",
    "LABEL=['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='Molecule', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.stars', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amidine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.acid', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.rotor', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.rtvFG', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_CNS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_mol_MW', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_dipole', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SASA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_FOSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_FISA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PISA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_WPSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_volume', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_donorHB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_accptHB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_dip.2.V', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_ACxDN..5.SA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_glob', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPpolrz', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPC16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPoct', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPw', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPo.w', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_CIQPlogS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogHERG', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPPCaco', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogBB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPPMDCK', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogKp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_IP.eV.', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_EA.eV.', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.metab', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogKhsa', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_HumanOralAbsorption', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PercentHumanOralAbsorption', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SAfluorine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SAamideO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.NandO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_RuleOfFive', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.ringatoms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.in34', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.in56', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.noncon', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.nonHatm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_RuleOfThree', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_ACxDN..5.SAxSASA.MW', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols=[tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(x=pd.DataFrame({j:data_set[j] for j in FEATURES}),\n",
    "                                              y=pd.Series(data_set[LABEL].values),\n",
    "                                              num_epochs=num_epochs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\saiva\\AppData\\Local\\Temp\\tmpysr6n_5p\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_model_dir': 'C:\\\\Users\\\\saiva\\\\AppData\\\\Local\\\\Temp\\\\tmpysr6n_5p', '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_save_summary_steps': 100, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "Classifier=tf.estimator.DNNClassifier(feature_columns=feature_cols, hidden_units=[51,51,30,20,10], n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-554cd92e844e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mML\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "Classifier.train(input_fn=get_input_fn(ML), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
