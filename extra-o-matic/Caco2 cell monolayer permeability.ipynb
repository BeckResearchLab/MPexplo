{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.tree import *\n",
    "from sklearn.metrics import r2_score, matthews_corrcoef\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 997)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atom=pd.read_csv('caco_AtomPair.tsv', sep='\\t', index_col=False)\n",
    "df_atom.shape\n",
    "#df_atom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 53)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dragon=pd.read_csv('caco_Dragon.tsv', sep='\\t', index_col=False)\n",
    "df_dragon.shape\n",
    "#pd.DataFrame.to_csv(df_dragon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quick=pd.read_csv('caco_QuickProp.tsv', sep='\\t', index_col=False)\n",
    "df_quick.shape\n",
    "#list(df_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 5402)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pipe_FP=pd.read_csv('caco_PipelinePilot_FP.tsv', sep='\\t', index_col=False)\n",
    "df_pipe_FP.shape\n",
    "#list(df_pipe_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Molecule', 'Class']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out=pd.read_csv('caco_Outcome.tsv', sep='\\t', index_col=False)\n",
    "list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_df=df_dragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_df.drop(x_df.columns[[1]], axis=1)\n",
    "#x_df\n",
    "x_df.set_index('Molecule', inplace=True)\n",
    "x_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXAiSZI6xXAiSZI65f8HdoPDD67T+RcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2153ecfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA().fit(x_df)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"variance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1403.35005891,    70.14091523, -1078.42492334,    71.07361064,\n",
       "          105.17401181],\n",
       "       [-1518.19296095,    24.38234516,  -584.63665113,   151.6492701 ,\n",
       "          122.57763524],\n",
       "       [-1620.40782624,   -75.573837  ,   288.86368747,    20.87305961,\n",
       "          -63.72261221],\n",
       "       ..., \n",
       "       [-1398.92385161,   -54.74747953,  -433.79676472,   -75.33341346,\n",
       "            8.36819284],\n",
       "       [ 2181.44166856,  -908.00519956,  -263.32172215,   -61.08337655,\n",
       "          -83.70085397],\n",
       "       [-1329.46514104,    57.54053375,  -497.93836616,    29.28824026,\n",
       "           30.79820622]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=5)\n",
    "x_pca=pca.fit_transform(x_df)\n",
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compound0001</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compound0002</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compound0003</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compound0004</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compound0005</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Molecule Class\n",
       "0  Compound0001     M\n",
       "1  Compound0002     L\n",
       "2  Compound0003     M\n",
       "3  Compound0004     M\n",
       "4  Compound0005     M"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df=df_out\n",
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class\n",
       "0     M\n",
       "1     L\n",
       "2     M\n",
       "3     M\n",
       "4     M"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final=y_df.drop('Molecule', axis=1)\n",
    "y_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df=train_test_split(x_pca, y_final, test_size=0.2)\n",
    "#x_train_int=table.Columns.RemoveAt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler=StandardScaler()\n",
    "clf_model=x_scaler.fit(x_train_df)\n",
    "x_train_norm=clf_model.transform(x_train_df)\n",
    "x_test_norm=clf_model.transform(x_test_df)\n",
    "x_train_norm.shape, x_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3036, 3), (760, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoder=LabelEncoder()\n",
    "y_encoded_tr=y_encoder.fit_transform(y_train_df)\n",
    "y_enc_tr=np_utils.to_categorical(y_encoded_tr)\n",
    "y_enc_tr.shape\n",
    "y_encoded_test=y_encoder.fit_transform(y_test_df)\n",
    "y_enc_test=np_utils.to_categorical(y_encoded_test)\n",
    "y_enc_tr.shape,y_enc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc_tr.shape[0], y_enc_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler=StandardScaler()\n",
    "y_scaler.fit(y_enc_tr)\n",
    "y_train_norm=y_scaler.transform(y_enc_tr)\n",
    "y_test_norm=y_scaler.transform(y_enc_test)\n",
    "y_train_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5, input_dim=5,init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(75, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(25, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))   \n",
    "    #model.add(Dense(12, init='normal', activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", kernel_initializer=\"normal\", input_dim=5)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 41.3021104917\n"
     ]
    }
   ],
   "source": [
    "#fit and evaluate the model\n",
    "estimators=[]\n",
    "#estimators.append(('standardise',StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=200, verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results=cross_val_score(pipeline, x_train_norm, y_train_norm, cv=kfold)\n",
    "print('accuracy:', results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3036, 5), (760, 5), (3036, 3), (760, 3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape, x_test_norm.shape, y_train_norm.shape, y_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final, y_test_final=train_test_split(y_final, test_size=0.2)\n",
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.518421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_linear=linear_model.LogisticRegression()\n",
    "model_linear=clf_linear.fit(x_train_norm, y_train_final)\n",
    "acc_logit=model_linear.score(x_test_norm, y_test_final)\n",
    "print('accuracy:',acc_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation of the confusion matrix for Logistic\n",
    "clf_logit_predict=clf_linear.predict(x_test_norm)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_final, clf_logit_predict)\n",
    "\n",
    "cmatrix_logit=confusion_matrix(y_test_final, clf_logit_predict)\n",
    "cmatrix_logit.diagonal()/cmatrix_logit.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.438157894737\n"
     ]
    }
   ],
   "source": [
    "tree_c=DecisionTreeClassifier(random_state=seed)#check this\n",
    "model_c=tree_c.fit(x_train_norm, y_train_final)\n",
    "acc_clf=model_c.score(x_test_norm, y_test_final)\n",
    "print('accuracy:', acc_clf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_c, out_file='tree_clf.dot', rounded=True)#visualizing the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of SGD: 0.498684210526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_SGD=linear_model.SGDClassifier(loss='epsilon_insensitive', penalty='none', alpha=0.0001)\n",
    "clf_SGD.fit(x_train_norm, y_train_final)\n",
    "y_predict_SGD=clf_SGD.predict(x_test_norm)\n",
    "acc_SGD=clf_SGD.score(x_test_norm, y_test_final)\n",
    "print('accuracy of SGD:', acc_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of svc: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc=SVC(kernel='rbf', C=1e3)\n",
    "clf_svc.fit(x_train_norm, y_train_final)\n",
    "y_predict_svc=clf_svc.predict(x_test_norm)\n",
    "acc_svc=clf_svc.score(x_test_norm, y_test_final)\n",
    "print(\"accuracy of svc:\", acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of randomforest: 0.455263157895\n",
      "order of classes ['H' 'L' 'M']\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=70)\n",
    "rf.fit(x_train_norm, y_train_final)\n",
    "rf_predict_norm=rf.predict(x_test_norm)\n",
    "acc_rf=rf.score(x_test_norm, y_test_final)\n",
    "print('accuracy of randomforest:', acc_rf)\n",
    "print('order of classes', rf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66,   3, 220],\n",
       "       [ 16,   1,  60],\n",
       "       [108,   7, 279]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the confusion matrix\n",
    "confusion_matrix(y_test_final, rf_predict_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2283737 ,  0.01298701,  0.70812183])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf=confusion_matrix(y_test_final, rf_predict_norm)\n",
    "cmatrix_rf.diagonal()/cmatrix_rf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary class modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(df_dragon), list(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dragon_mrg=pd.merge(df_quick, df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_dragon_mrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HM model\n",
    "a=df_dragon_mrg[df_out['Class']=='H']\n",
    "b=df_dragon_mrg[df_out['Class']=='M']\n",
    "frames_hm=[a, b]\n",
    "HM=pd.concat(frames_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ML model\n",
    "c=df_dragon_mrg[df_out['Class']=='M']\n",
    "d=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_ml=[c,d]\n",
    "ML=pd.concat(frames_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2406, 53)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, ..., 0, 9, 0],\n",
       "       [0, 2, 0, ..., 7, 38, 1],\n",
       "       [0, 2, 0, ..., 8, 39, 1],\n",
       "       ..., \n",
       "       [19, 1, 1, ..., 4, 72, 2],\n",
       "       [0, 0, 0, ..., 4, 19, 0],\n",
       "       [0, 1, 0, ..., 4, 24, 0]], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ML=ML.values[:, 1:51]\n",
    "x_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', ..., 'L', 'L', 'L'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ML=ML.values[:, 52]\n",
    "y_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_x_train, ML_x_test, ML_y_train, ML_y_test = train_test_split(x_ML, y_ML, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HL model\n",
    "e=df_dragon_mrg[df_out['Class']=='H']\n",
    "f=df_dragon_mrg[df_out['Class']=='L']\n",
    "frames_hl=[e,f]\n",
    "HL=pd.concat(frames_hl)\n",
    "#HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1767, 53)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_HL=HL.values[:,1:51]\n",
    "y_HL=HL.values[:, 52]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HL_x_train, HL_x_test, HL_y_train, HL_y_test=train_test_split(x_HL, y_HL, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.   0.   0. ...,   0.  11.   0.]\n",
      " [  0.   0.   0. ...,   0.  11.   0.]\n",
      " [  1.   1.   0. ...,   9.  41.   0.]\n",
      " ..., \n",
      " [  0.   0.   0. ...,   7.  23.   0.]\n",
      " [  0.   1.   0. ...,   5.  28.   0.]\n",
      " [  0.   1.   0. ...,   2.  21.   0.]]\n"
     ]
    }
   ],
   "source": [
    "x_HM=HM.values[:, 1:51].astype('float32')\n",
    "print(x_HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'H', 'H', ..., 'M', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_HM=HM.values[:, 52]\n",
    "y_HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HM_x_train, HM_x_test, HM_y_train, HM_y_test=train_test_split(x_HM,y_HM, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HM_y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Decision tree model for HM class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.0848329   0.9151671 ]\n",
      " [ 0.0848329   0.9151671 ]\n",
      " [ 0.88282504  0.11717496]\n",
      " ..., \n",
      " [ 0.0848329   0.9151671 ]\n",
      " [ 0.34624697  0.65375303]\n",
      " [ 0.88282504  0.11717496]]\n",
      "accuracy for HM model: 0.880116959064\n",
      "mcc for the CART for HM: 0.743578882513\n"
     ]
    }
   ],
   "source": [
    "tree_hm=DecisionTreeClassifier(min_weight_fraction_leaf=0.13, max_leaf_nodes=12)\n",
    "tree_hm.fit(HM_x_train, HM_y_train)\n",
    "acc_hm=tree_hm.score(HM_x_test, HM_y_test)\n",
    "tree_hm_predict=tree_hm.predict(HM_x_test)\n",
    "\n",
    "#matthews correlation coefficient\n",
    "matt_tree_hm=matthews_corrcoef(HM_y_test, tree_hm_predict)\n",
    "\n",
    "print(tree_hm.classes_)\n",
    "print(tree_hm.predict_proba(HM_x_test))\n",
    "print('accuracy for HM model:',acc_hm)\n",
    "print('mcc for the CART for HM:', matt_tree_hm)\n",
    "#mcc of the literature value for only the CART model is 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37390871055829272, 0.62609128944170733)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=tree_hm.predict_proba(HM_x_test)\n",
    "z[:,0].mean(), z[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[206,  55],\n",
       "       [ 27, 396]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for tree in HM\n",
    "confusion_matrix(HM_y_test, tree_hm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78927203,  0.93617021])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_tree_hm=confusion_matrix(HM_y_test, tree_hm_predict)\n",
    "cmatrix_tree_hm.diagonal()/cmatrix_tree_hm.sum(axis=1)\n",
    "#LITERATURE VALUE OF THE CONSENSUS MODEL\n",
    "#H:0.78\n",
    "#M:0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting the receiver operating characteristic curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "roc_auc=dict()\n",
    "HM_y_test_col=HM_y_test[:,None]\n",
    "tree_hm_predict_col=tree_hm_predict[:,None]\n",
    "#y_tree_ml=tree_hm.fit(HM_x_train, HM_y_train)\n",
    "for i in range(0,1):\n",
    "    fpr[i], tpr[i], _=roc_curve(label_binarize(HM_y_test_col[:,i], classes=['H', 'M']),\n",
    "                                label_binarize(tree_hm_predict_col[:,i], classes=['H','M']))\n",
    "    roc_auc[i]=auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4wxxoSdBSDGGGOMCbv/D4K1HccHFBTQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2360edb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange', lw=lw, label='ROC curve(area=%f)' % roc_auc[0])\n",
    "plt.plot([0,1.0], [0, 1.0], color='blue', linestyle='--')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for CART for HM')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chiad tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CHAID import Tree\n",
    "\n",
    "#CHAID input parameters\n",
    "indep_variable_cols=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW']\n",
    "dep_variable=[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip(indep_variable_cols,['nominal']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tree from pandas\n",
    "tree_chaid= Tree.from_pandas_df(HM, dict(zip(indep_variable_cols, ['nominal']*3)), dep_variable, \n",
    "                          max_depth=4, min_parent_node_size=80, min_child_node_size=35)\n",
    "#tree.to_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest classifier for HM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'M']\n",
      "[[ 0.          1.        ]\n",
      " [ 0.10526316  0.89473684]\n",
      " [ 1.          0.        ]\n",
      " ..., \n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]]\n",
      "accuracy of Random forest for HM model is: 0.941520467836\n",
      "mcc: 0.875831383053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=95, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm=RandomForestClassifier(n_estimators=95, random_state=1)\n",
    "RF_hm.fit(HM_x_train, HM_y_train)\n",
    "RF_hm_predict= RF_hm.predict(HM_x_test)\n",
    "acc_RF_HM=RF_hm.score(HM_x_test, HM_y_test)\n",
    "\n",
    "print(RF_hm.classes_)\n",
    "print(RF_hm.predict_proba(HM_x_test))\n",
    "print('accuracy of Random forest for HM model is:', acc_RF_HM)\n",
    "\n",
    "\n",
    "#matthews correlation coefficient\n",
    "matt_corr_HM=matthews_corrcoef(HM_y_test, RF_hm_predict)\n",
    "print('mcc:',matt_corr_HM)\n",
    "\n",
    "RF_hm.get_params\n",
    "\n",
    "#MCC OF THE LITERATURE VALUE FOR THE HM RF IS 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[232,  29],\n",
       "       [ 11, 412]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(HM_y_test, RF_hm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88888889,  0.97399527])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_hm=confusion_matrix(HM_y_test, RF_hm_predict)\n",
    "cmatrix_rf_hm.diagonal()/cmatrix_rf_hm.sum(axis=1)\n",
    "#LITERATURE VALUE FOR consensus model\n",
    "#H:0.78\n",
    "#M:0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RF_hm_predict, HM_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(y_HM, classes=['H', 'M'])\n",
    "n_classes=y.shape[1]\n",
    "#roc\n",
    "fpr=dict()\n",
    "tpr=dict()\n",
    "roc_auc=dict()\n",
    "HM_y_test_col=HM_y_test[:, None]\n",
    "RF_hm_predict_col=RF_hm_predict[:,None]\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _= roc_curve(label_binarize(HM_y_test_col[:,i], classes=['H','M']), \n",
    "                                 label_binarize(RF_hm_predict_col[:,i], classes=['H','M']))\n",
    "    roc_auc[i]= auc(fpr[i], tpr[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcYUOgtAjDHGGFPo/j+PojnFmIS/bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2362171d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the ROC curve\n",
    "plt.figure()\n",
    "lw=2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange', lw=lw, label='ROC curve (area=%f)' % roc_auc[0])\n",
    "plt.plot([0,1],[0,1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for RF for HM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22,   8,  34],\n",
       "       [  5,   1,   3],\n",
       "       [262,  68, 357]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation of confustion matrix\n",
    "confusion_matrix(y_predict_svc, y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm_predict_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'H', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H',\n",
       "       'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'H', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M',\n",
       "       'H', 'M', 'H', 'H', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H',\n",
       "       'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H', 'H', 'M', 'H',\n",
       "       'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H',\n",
       "       'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'H',\n",
       "       'H', 'H', 'H', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'M', 'M', 'H', 'H', 'M', 'H', 'H', 'M', 'H', 'M', 'M', 'H', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'H', 'H', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'M', 'M', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M',\n",
       "       'M', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'H', 'H', 'H', 'H', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'H', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'H', 'M',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'M',\n",
       "       'H', 'H', 'H', 'M', 'H', 'M', 'H', 'H', 'M', 'H', 'H', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'H', 'H', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'M',\n",
       "       'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'H',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'H',\n",
       "       'M', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'M', 'M', 'M', 'H', 'M',\n",
       "       'H', 'H', 'H', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'H', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H', 'M', 'H',\n",
       "       'M', 'H', 'M', 'H', 'H', 'M', 'M', 'H', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H',\n",
       "       'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'M', 'H'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_hm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vote1=RF_hm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'H', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H',\n",
       "       'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M',\n",
       "       'H', 'H', 'H', 'H', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'M', 'H', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H',\n",
       "       'M', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'H',\n",
       "       'H', 'H', 'M', 'M', 'M', 'H', 'H', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'M', 'M', 'H', 'H', 'M', 'H', 'H', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'M', 'M', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'M', 'M', 'H', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'H', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'H', 'H', 'H', 'M',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'M', 'M',\n",
       "       'M', 'H', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'M', 'M', 'H',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'H', 'M',\n",
       "       'M', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'H',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'M', 'H', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H', 'H',\n",
       "       'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'M', 'H', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'M', 'H', 'M', 'H',\n",
       "       'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'H', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H',\n",
       "       'M', 'M', 'H', 'H', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M',\n",
       "       'M', 'H', 'M', 'H', 'M', 'H', 'M', 'H', 'M', 'M', 'M', 'H', 'M',\n",
       "       'H', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M',\n",
       "       'M', 'M', 'H', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'H', 'H', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'H', 'M', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'H',\n",
       "       'H', 'M', 'M', 'M', 'H', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'H', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M', 'H', 'M', 'H',\n",
       "       'M', 'H', 'H', 'H', 'H', 'M', 'M', 'H', 'H', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'H',\n",
       "       'H', 'H', 'H', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'H', 'M', 'M',\n",
       "       'M', 'H', 'H', 'H', 'M', 'M', 'M', 'H'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vote2=tree_hm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#voting for a binary model\n",
    "consensus=[]\n",
    "for i in range(0, 684):\n",
    "    if Vote1[i]==Vote2[i]:\n",
    "        consensus.append(Vote1[i])\n",
    "    else:\n",
    "        consensus.append('NC')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'H',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'H',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'NC',\n",
       " 'H',\n",
       " 'NC',\n",
       " 'M',\n",
       " 'M',\n",
       " 'M',\n",
       " 'H']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NN FOR CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((684, 2), (2735, 2))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "y_encoder=LabelEncoder()\n",
    "y_encoded_tr_HM=y_encoder.fit_transform(HM_y_train)\n",
    "y_en_tr_HM=np_utils.to_categorical(y_encoded_tr_HM)\n",
    "y_en_tr_HM.shape\n",
    "y_encoded_test_HM=y_encoder.fit_transform(HM_y_test)\n",
    "y_en_test_HM=np_utils.to_categorical(y_encoded_test_HM)\n",
    "y_en_test_HM.shape, y_en_tr_HM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2735, 2), (684, 2))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler=StandardScaler()\n",
    "y_scaler.fit(y_en_tr_HM)\n",
    "HM_y_train_norm=y_scaler.transform(y_en_tr_HM)\n",
    "HM_y_test_norm=y_scaler.transform(y_en_test_HM)\n",
    "HM_y_train_norm.shape, HM_y_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2735, 50), (684, 50))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HM_x_train.shape, HM_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2735, 50)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaler=StandardScaler()\n",
    "x_scaler.fit(HM_x_train)\n",
    "HM_x_train_norm=x_scaler.transform(HM_x_train)\n",
    "HM_x_test_norm=x_scaler.transform(HM_x_test)\n",
    "HM_x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(51, input_dim=51, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(26, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(13, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, init='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(51, activation=\"relu\", kernel_initializer=\"normal\", input_dim=51)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(26, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(13, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "C:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_31_input to have shape (None, 51) but got array with shape (2461, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-77343321d312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHM_x_train_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHM_y_train_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_31_input to have shape (None, 51) but got array with shape (2461, 50)"
     ]
    }
   ],
   "source": [
    "#fit and evaluate the model\n",
    "estimators=[]\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=baseline_model, nb_epoch=100, batch_size=20, verbose=0)))\n",
    "pipeline=Pipeline(estimators)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results=cross_val_score(pipeline, HM_x_train_norm, HM_y_train_norm, cv=kfold)\n",
    "print('accuracy:', results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision tree classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.05, presort=False,\n",
      "            random_state=None, splitter='best')>\n",
      "accuracy for the CT for ML model: 0.94398340249\n",
      "probability predictions for ML model: [[ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25490196  0.74509804]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03875969  0.96124031]\n",
      " [ 0.14285714  0.85714286]\n",
      " [ 0.09923664  0.90076336]\n",
      " [ 0.          1.        ]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.          1.        ]\n",
      " [ 0.93277311  0.06722689]\n",
      " [ 0.8556701   0.1443299 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36        0.64      ]]\n",
      "matthews correlation coeff: 0.776354970695\n"
     ]
    }
   ],
   "source": [
    "tree_ml=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_ml.fit(ML_x_train, ML_y_train)\n",
    "acc_tree_ml=tree_ml.score(ML_x_test, ML_y_test)\n",
    "prob_tree_ml=tree_ml.predict_proba(ML_x_test)\n",
    "predict_tree_ml=tree_ml.predict(ML_x_test)\n",
    "\n",
    "print('order of classes:',tree_ml.classes_)\n",
    "print(tree_ml.get_params)\n",
    "print('accuracy for the CT for ML model:', acc_tree_ml)\n",
    "print('probability predictions for ML model:', prob_tree_ml)\n",
    "\n",
    "#matthews correlation coefficient\n",
    "mat_corr_ML=matthews_corrcoef(ML_y_test, predict_tree_ml)\n",
    "print('matthews correlation coeff:',mat_corr_ML)\n",
    "\n",
    "#len(acc_tree_ml),len(ML_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54,  22],\n",
       "       [  5, 401]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix\n",
    "confusion_matrix(ML_y_test, predict_tree_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71052632,  0.98768473])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the accuracies of the predictions of the individual classes\n",
    "cmatrix_ML_tree=confusion_matrix(ML_y_test, predict_tree_ml)\n",
    "cmatrix_ML_tree.diagonal()/cmatrix_ML_tree.sum(axis=1)\n",
    "#literature values of L and M class respectively, ONLY FOR CART MODELS\n",
    "#L:0.83\n",
    "#M:0.70\n",
    "#literature values of L and M on the consensus system\n",
    "#L:0.79\n",
    "#M:0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['L' 'M']\n",
      "accuracy of model: 0.952282157676\n",
      "probabilities of the respective classes: [[ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 1.          0.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86956522  0.13043478]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.7826087   0.2173913 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.19565217  0.80434783]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.73913043  0.26086957]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 1.          0.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.2173913   0.7826087 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.30434783  0.69565217]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26086957  0.73913043]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.13043478  0.86956522]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.69565217  0.30434783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.43478261  0.56521739]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.52173913  0.47826087]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.17391304  0.82608696]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39130435  0.60869565]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.56521739  0.43478261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.60869565  0.39130435]\n",
      " [ 0.          1.        ]\n",
      " [ 0.47826087  0.52173913]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.34782609  0.65217391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08695652  0.91304348]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.82608696  0.17391304]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04347826  0.95652174]]\n",
      "matthews correlation coefficient: 0.816081284936\n",
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=23, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "RF_ml=RandomForestClassifier(n_estimators=23, random_state=2)\n",
    "RF_ml.fit(ML_x_train, ML_y_train)\n",
    "accu_RF_ml=RF_ml.score(ML_x_test, ML_y_test)\n",
    "prob_RF_ml=RF_ml.predict_proba(ML_x_test)\n",
    "predict_RF_ml=RF_ml.predict(ML_x_test)\n",
    "#matthews correlation coefficients\n",
    "matt_coeff_ml=matthews_corrcoef(ML_y_test, predict_RF_ml)\n",
    "\n",
    "print('order of classes:',RF_ml.classes_)\n",
    "print('accuracy of model:', accu_RF_ml)\n",
    "print('probabilities of the respective classes:', prob_RF_ml)\n",
    "print('matthews correlation coefficient:', matt_coeff_ml )\n",
    "print(RF_ml.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62,  14],\n",
       "       [  9, 397]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for random forest\n",
    "confusion_matrix(ML_y_test, predict_RF_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81578947,  0.97783251])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_ml=confusion_matrix(ML_y_test, predict_RF_ml)\n",
    "cmatrix_rf_ml.diagonal()/cmatrix_rf_ml.sum(axis=1)\n",
    "\n",
    "#literature values of the consensus system for L and M classes respectively\n",
    "#L:0.79\n",
    "#M:0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree for the LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of the model 0.937853107345\n",
      "probabilities of the classes: [[ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 0.          1.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 0.79487179  0.20512821]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.10588235  0.89411765]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.84210526  0.15789474]\n",
      " [ 0.01408451  0.98591549]\n",
      " [ 0.5915493   0.4084507 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 0.98591549  0.01408451]\n",
      " [ 1.          0.        ]]\n",
      "prediction of classes: ['L' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'L' 'L'\n",
      " 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H']\n",
      "matthews correlation coeff: 0.802765694238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.05, presort=False,\n",
       "            random_state=None, splitter='best')>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_LH=DecisionTreeClassifier(min_weight_fraction_leaf=0.05, max_leaf_nodes=10)\n",
    "tree_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_tree_LH=tree_LH.score(HL_x_test, HL_y_test)\n",
    "predict_tree_LH=tree_LH.predict(HL_x_test)\n",
    "prob_tree_LH=tree_LH.predict_proba(HL_x_test)\n",
    "#matthews correlation coeff\n",
    "matt_corrcoef= matthews_corrcoef(HL_y_test, predict_tree_LH)\n",
    "print('order of classes:', tree_LH.classes_)\n",
    "print(\"accuracy of the model\", acc_tree_LH)\n",
    "print('probabilities of the classes:', prob_tree_LH)\n",
    "print('prediction of classes:', predict_tree_LH)\n",
    "print('matthews correlation coeff:', matt_corrcoef)\n",
    "\n",
    "tree_LH.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[276,   5],\n",
       "       [ 17,  56]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix\n",
    "confusion_matrix(HL_y_test, predict_tree_LH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98220641,  0.76712329])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_HL_tree=confusion_matrix(HL_y_test, predict_tree_LH)\n",
    "cmatrix_HL_tree.diagonal()/cmatrix_HL_tree.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest for LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order of classes: ['H' 'L']\n",
      "accuracy of model: 0.957627118644\n",
      "probabilities of the respective classes: [[ 0.08510638  0.91489362]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.5106383   0.4893617 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04255319  0.95744681]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.91489362  0.08510638]\n",
      " [ 0.          1.        ]\n",
      " [ 0.38297872  0.61702128]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.65957447  0.34042553]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.14893617  0.85106383]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 0.80851064  0.19148936]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.69503546  0.30496454]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.44680851  0.55319149]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.65957447  0.34042553]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87234043  0.12765957]\n",
      " [ 1.          0.        ]\n",
      " [ 0.14893617  0.85106383]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.19148936  0.80851064]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.04255319  0.95744681]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 0.          1.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 0.89361702  0.10638298]\n",
      " [ 1.          0.        ]\n",
      " [ 0.19148936  0.80851064]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.23404255  0.76595745]\n",
      " [ 0.          1.        ]\n",
      " [ 0.55319149  0.44680851]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.29787234  0.70212766]\n",
      " [ 1.          0.        ]\n",
      " [ 0.74468085  0.25531915]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.40425532  0.59574468]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 1.          0.        ]\n",
      " [ 0.61702128  0.38297872]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.85106383  0.14893617]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.76595745  0.23404255]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 1.          0.        ]\n",
      " [ 0.27659574  0.72340426]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.14893617  0.85106383]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.63829787  0.36170213]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.46808511  0.53191489]\n",
      " [ 0.19148936  0.80851064]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.46808511  0.53191489]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.57446809  0.42553191]\n",
      " [ 1.          0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.82978723  0.17021277]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.78723404  0.21276596]\n",
      " [ 0.          1.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.93617021  0.06382979]\n",
      " [ 0.06382979  0.93617021]\n",
      " [ 1.          0.        ]\n",
      " [ 0.9787234   0.0212766 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.0212766   0.9787234 ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.95744681  0.04255319]\n",
      " [ 0.          1.        ]\n",
      " [ 0.5106383   0.4893617 ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]\n",
      " [ 1.          0.        ]]\n",
      "predictions of the model: ['L' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'L' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'L' 'L' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'L' 'H'\n",
      " 'H' 'L' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'L' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'L' 'L' 'L' 'H' 'H' 'H' 'L' 'L'\n",
      " 'L' 'L' 'H' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'L' 'H' 'H' 'L'\n",
      " 'H' 'H' 'H' 'L' 'H' 'H' 'L' 'H' 'H' 'H' 'H' 'H']\n",
      "matthews correlation coefficient: 0.86805438582\n"
     ]
    }
   ],
   "source": [
    "RF_LH=RandomForestClassifier(n_estimators=47, random_state=3)\n",
    "RF_LH.fit(HL_x_train, HL_y_train)\n",
    "acc_RF_HL=RF_LH.score(HL_x_test, HL_y_test)\n",
    "predict_RF_HL=RF_LH.predict(HL_x_test)\n",
    "prob_RF_HL=RF_LH.predict_proba(HL_x_test)\n",
    "#matthews correlation coefficient\n",
    "matt_corrcoeff_lh=matthews_corrcoef(HL_y_test, predict_RF_HL)\n",
    "\n",
    "print('order of classes:', RF_LH.classes_)\n",
    "print('accuracy of model:', acc_RF_HL)\n",
    "print('probabilities of the respective classes:', prob_RF_HL)\n",
    "print('predictions of the model:', predict_RF_HL )\n",
    "print('matthews correlation coefficient:', matt_corrcoeff_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[276,   5],\n",
       "       [ 10,  63]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the confusion matrix for HL rf\n",
    "confusion_matrix(HL_y_test, predict_RF_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98220641,  0.8630137 ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix_rf_HL=confusion_matrix(HL_y_test, predict_RF_HL)\n",
    "cmatrix_rf_HL.diagonal()/cmatrix_rf_HL.sum(axis=1)\n",
    "\n",
    "#LITERATURE VALUE FOR THE LH MODEL FOR ONLY RF\n",
    "#H:0.95\n",
    "#L:0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**BUILDING A CLASSIFICATION MODEL IN TENSORFLOW FOR LH model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1413, 53), (354, 53))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set, test_set=train_test_split(HL, test_size=0.2)\n",
    "training_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLUMNS=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW','Class']\n",
    "FEATURES=['Molecule','QikProp_.stars','QikProp_.amine','QikProp_.amidine','QikProp_.acid',\n",
    " 'QikProp_.amide','QikProp_.rotor','QikProp_.rtvFG','QikProp_CNS','QikProp_mol_MW','QikProp_dipole','QikProp_SASA','QikProp_FOSA',\n",
    " 'QikProp_FISA','QikProp_PISA','QikProp_WPSA', 'QikProp_volume','QikProp_donorHB','QikProp_accptHB','QikProp_dip.2.V','QikProp_ACxDN..5.SA',\n",
    " 'QikProp_glob','QikProp_QPpolrz','QikProp_QPlogPC16','QikProp_QPlogPoct','QikProp_QPlogPw','QikProp_QPlogPo.w',\n",
    "'QikProp_QPlogS','QikProp_CIQPlogS','QikProp_QPlogHERG','QikProp_QPPCaco','QikProp_QPlogBB','QikProp_QPPMDCK','QikProp_QPlogKp',\n",
    " 'QikProp_IP.eV.','QikProp_EA.eV.','QikProp_.metab','QikProp_QPlogKhsa','QikProp_HumanOralAbsorption','QikProp_PercentHumanOralAbsorption','QikProp_SAfluorine',\n",
    " 'QikProp_SAamideO','QikProp_PSA', 'QikProp_.NandO','QikProp_RuleOfFive','QikProp_.ringatoms','QikProp_.in34','QikProp_.in56','QikProp_.noncon',\n",
    " 'QikProp_.nonHatm','QikProp_RuleOfThree','QikProp_ACxDN..5.SAxSASA.MW']\n",
    "LABEL=['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='Molecule', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.stars', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amidine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.acid', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.amide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.rotor', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.rtvFG', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_CNS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_mol_MW', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_dipole', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SASA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_FOSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_FISA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PISA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_WPSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_volume', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_donorHB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_accptHB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_dip.2.V', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_ACxDN..5.SA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_glob', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPpolrz', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPC16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPoct', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPw', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogPo.w', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_CIQPlogS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogHERG', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPPCaco', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogBB', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPPMDCK', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogKp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_IP.eV.', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_EA.eV.', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.metab', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_QPlogKhsa', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_HumanOralAbsorption', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PercentHumanOralAbsorption', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SAfluorine', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_SAamideO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_PSA', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.NandO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_RuleOfFive', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.ringatoms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.in34', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.in56', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.noncon', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_.nonHatm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_RuleOfThree', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='QikProp_ACxDN..5.SAxSASA.MW', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols=[tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(x=pd.DataFrame({j:data_set[j] for j in FEATURES}),\n",
    "                                              y=pd.Series(data_set[LABEL].values),\n",
    "                                              num_epochs=num_epochs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\saiva\\AppData\\Local\\Temp\\tmp1r8pjc7o\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\saiva\\\\AppData\\\\Local\\\\Temp\\\\tmp1r8pjc7o', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "Classifier=tf.estimator.DNNClassifier(feature_columns=feature_cols, hidden_units=[51,51,30,20,10], n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-554cd92e844e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mML\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-bb2b0bbd58ae>\u001b[0m in \u001b[0;36mget_input_fn\u001b[0;34m(data_set, num_epochs, shuffle)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     return tf.estimator.inputs.pandas_input_fn(x=pd.DataFrame({j:data_set[j] for j in FEATURES}),\n\u001b[0;32m----> 3\u001b[0;31m                                               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                               num_epochs=num_epochs, shuffle=shuffle)\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 243\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\saiva\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2950\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2951\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "Classifier.train(input_fn=get_input_fn(ML), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
